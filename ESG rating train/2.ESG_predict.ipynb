{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ESG_labeling(x):\n",
    "    \n",
    "    if x == 0:\n",
    "        x = 'A+'\n",
    "    \n",
    "    elif x ==  1:\n",
    "        x = 'A'\n",
    "        \n",
    "    elif x == 2:\n",
    "        x = 'B+'\n",
    "    \n",
    "    elif x == 3:\n",
    "        x = 'B'\n",
    "        \n",
    "    elif x == 4:\n",
    "        x = 'C'\n",
    "        \n",
    "    elif x == 5:\n",
    "        x = 'D'\n",
    "        \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>0.280724</td>\n",
       "      <td>0.103535</td>\n",
       "      <td>0.048822</td>\n",
       "      <td>0.042298</td>\n",
       "      <td>0.126684</td>\n",
       "      <td>0.236742</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>BGF리테일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.067251</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102339</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>BNK금융지주</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>BYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>CJ CGV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.100976</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>0.300113</td>\n",
       "      <td>0.067755</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>0.089152</td>\n",
       "      <td>CJ대한통운</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>255</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>효성화학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>휠라홀딩스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>257</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>휴비스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>휴켐스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.033730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>흥국화재</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Topic_0   Topic_1   Topic_2   Topic_3   Topic_4   Topic_5  \\\n",
       "0             0  0.039983  0.280724  0.103535  0.048822  0.042298  0.126684   \n",
       "1             1  0.236842  0.067251  0.210526  0.315789  0.000000  0.102339   \n",
       "2             2  0.000000  0.000000  0.625000  0.000000  0.000000  0.250000   \n",
       "3             3  0.125000  0.239583  0.218750  0.177083  0.000000  0.114583   \n",
       "4             4  0.100976  0.111486  0.071321  0.239865  0.300113  0.067755   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "255         255  0.444444  0.203704  0.000000  0.166667  0.000000  0.148148   \n",
       "256         256  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "257         257  0.058824  0.147059  0.117647  0.176471  0.058824  0.382353   \n",
       "258         258  0.000000  0.500000  0.000000  0.166667  0.000000  0.000000   \n",
       "259         259  0.077381  0.033730  0.500000  0.019841  0.025794  0.303571   \n",
       "\n",
       "      Topic_6   Topic_7  company  \n",
       "0    0.236742  0.121212   BGF리테일  \n",
       "1    0.035088  0.032164  BNK금융지주  \n",
       "2    0.125000  0.000000      BYC  \n",
       "3    0.062500  0.062500   CJ CGV  \n",
       "4    0.019332  0.089152   CJ대한통운  \n",
       "..        ...       ...      ...  \n",
       "255  0.037037  0.000000     효성화학  \n",
       "256  1.000000  0.000000    휠라홀딩스  \n",
       "257  0.000000  0.058824      휴비스  \n",
       "258  0.333333  0.000000      휴켐스  \n",
       "259  0.039683  0.000000     흥국화재  \n",
       "\n",
       "[260 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#사회 부문 예측\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "news_data = pd.read_csv('topic_variable.csv')\n",
    "\n",
    "#유의적인 변수만을 변수로 선택함\n",
    "\n",
    "#news_variable = news_data[['company','Topic_2','Topic_7','Topic_3']] \n",
    "\n",
    "#전체 변수 선택 시\n",
    "news_variable = news_data.drop(['date','합계'],axis = 1)\n",
    "\n",
    "news_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>star</th>\n",
       "      <th>up</th>\n",
       "      <th>wel</th>\n",
       "      <th>wl</th>\n",
       "      <th>cul</th>\n",
       "      <th>management</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BYC</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CJ CGV</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CJ씨푸드</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>휴켐스</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>흥국화재</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>한전기술</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>현대중공업지주</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>종근당홀딩스</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  star   up  wel   wl  cul  management\n",
       "0     BGF리테일   3.0  3.0  2.8  2.7  2.8         2.5\n",
       "1        BYC   2.3  1.8  3.3  2.3  1.9         1.8\n",
       "2     CJ CGV   3.5  3.6  3.0  3.3  3.1         2.9\n",
       "3     CJ대한통운   2.8  2.9  2.2  2.6  2.9         2.4\n",
       "4      CJ씨푸드   3.1  3.3  2.7  2.9  2.8         2.6\n",
       "..       ...   ...  ...  ...  ...  ...         ...\n",
       "244      휴켐스   2.8  3.8  2.7  2.5  2.8         2.4\n",
       "245     흥국화재   2.6  2.3  2.8  2.5  2.5         2.2\n",
       "246     한전기술   3.9  3.9  4.3  4.0  3.7         3.0\n",
       "247  현대중공업지주   2.9  2.9  3.1  2.6  2.9         2.2\n",
       "248   종근당홀딩스   2.9  3.4  2.4  2.2  2.9         2.1\n",
       "\n",
       "[249 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data = pd.read_csv('job_all_data.csv',encoding = 'cp949')\n",
    "\n",
    "job_variable = job_data.iloc[0:,1:7]\n",
    "\n",
    "job_variable = pd.concat([job_data['회사명'],job_variable],axis=1)\n",
    "\n",
    "job_variable.columns = ['company', 'star', 'up', 'wel', 'wl','cul','management']\n",
    "\n",
    "job_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>fi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>2.308304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BYC</td>\n",
       "      <td>0.664337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CJ CGV</td>\n",
       "      <td>2.477649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>7.220688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CJ씨푸드</td>\n",
       "      <td>0.135332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>현대에너지솔루션</td>\n",
       "      <td>0.459174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>휴켐스</td>\n",
       "      <td>0.846391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>한전기술</td>\n",
       "      <td>0.699244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>현대중공업지주</td>\n",
       "      <td>7.727859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>종근당홀딩스</td>\n",
       "      <td>0.393472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      company        fi\n",
       "0      BGF리테일  2.308304\n",
       "1         BYC  0.664337\n",
       "2      CJ CGV  2.477649\n",
       "3      CJ대한통운  7.220688\n",
       "4       CJ씨푸드  0.135332\n",
       "..        ...       ...\n",
       "244  현대에너지솔루션  0.459174\n",
       "245       휴켐스  0.846391\n",
       "246      한전기술  0.699244\n",
       "247   현대중공업지주  7.727859\n",
       "248    종근당홀딩스  0.393472\n",
       "\n",
       "[249 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_variable = pd.read_csv('fi_all_data.csv',encoding = 'cp949')\n",
    "fi_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK홀딩스</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BGF</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNK금융지주</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>효성첨단소재</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>효성티앤씨</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>효성화학</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>휠라홀딩스</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>휴비스</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>763 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     company result\n",
       "0     AJ네트웍스      B\n",
       "1      AK홀딩스     B+\n",
       "2        BGF      A\n",
       "3     BGF리테일      A\n",
       "4    BNK금융지주     A+\n",
       "..       ...    ...\n",
       "758   효성첨단소재      A\n",
       "759    효성티앤씨      A\n",
       "760     효성화학      A\n",
       "761    휠라홀딩스      A\n",
       "762      휴비스      A\n",
       "\n",
       "[763 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ESG 등급\n",
    "\n",
    "ESG = pd.read_csv('ESG_rating.csv', encoding = 'cp949')\n",
    "\n",
    "ESG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>company</th>\n",
       "      <th>star</th>\n",
       "      <th>up</th>\n",
       "      <th>wel</th>\n",
       "      <th>wl</th>\n",
       "      <th>cul</th>\n",
       "      <th>management</th>\n",
       "      <th>fi</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>0.280724</td>\n",
       "      <td>0.103535</td>\n",
       "      <td>0.048822</td>\n",
       "      <td>0.042298</td>\n",
       "      <td>0.126684</td>\n",
       "      <td>0.236742</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.308304</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>BYC</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.664337</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>CJ CGV</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.477649</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.100976</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>0.300113</td>\n",
       "      <td>0.067755</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>0.089152</td>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.220688</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.056026</td>\n",
       "      <td>0.180791</td>\n",
       "      <td>0.165254</td>\n",
       "      <td>0.054614</td>\n",
       "      <td>0.075330</td>\n",
       "      <td>0.078311</td>\n",
       "      <td>0.193817</td>\n",
       "      <td>0.195857</td>\n",
       "      <td>CJ제일제당</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>9.538798</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>255</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>효성화학</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.564620</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>휠라홀딩스</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.662624</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>257</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>휴비스</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.793223</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>휴켐스</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.846391</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>259</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.033730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>흥국화재</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>13.211184</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Topic_0   Topic_1   Topic_2   Topic_3   Topic_4   Topic_5  \\\n",
       "0             0  0.039983  0.280724  0.103535  0.048822  0.042298  0.126684   \n",
       "1             2  0.000000  0.000000  0.625000  0.000000  0.000000  0.250000   \n",
       "2             3  0.125000  0.239583  0.218750  0.177083  0.000000  0.114583   \n",
       "3             4  0.100976  0.111486  0.071321  0.239865  0.300113  0.067755   \n",
       "4             5  0.056026  0.180791  0.165254  0.054614  0.075330  0.078311   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "235         255  0.444444  0.203704  0.000000  0.166667  0.000000  0.148148   \n",
       "236         256  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "237         257  0.058824  0.147059  0.117647  0.176471  0.058824  0.382353   \n",
       "238         258  0.000000  0.500000  0.000000  0.166667  0.000000  0.000000   \n",
       "239         259  0.077381  0.033730  0.500000  0.019841  0.025794  0.303571   \n",
       "\n",
       "      Topic_6   Topic_7 company  star   up  wel   wl  cul  management  \\\n",
       "0    0.236742  0.121212  BGF리테일   3.0  3.0  2.8  2.7  2.8         2.5   \n",
       "1    0.125000  0.000000     BYC   2.3  1.8  3.3  2.3  1.9         1.8   \n",
       "2    0.062500  0.062500  CJ CGV   3.5  3.6  3.0  3.3  3.1         2.9   \n",
       "3    0.019332  0.089152  CJ대한통운   2.8  2.9  2.2  2.6  2.9         2.4   \n",
       "4    0.193817  0.195857  CJ제일제당   2.9  3.0  2.6  3.0  3.0         2.5   \n",
       "..        ...       ...     ...   ...  ...  ...  ...  ...         ...   \n",
       "235  0.037037  0.000000    효성화학   2.3  1.9  2.8  2.4  2.5         1.7   \n",
       "236  1.000000  0.000000   휠라홀딩스   2.8  2.8  2.9  2.4  2.9         2.3   \n",
       "237  0.000000  0.058824     휴비스   3.1  3.4  2.9  2.8  3.2         2.5   \n",
       "238  0.333333  0.000000     휴켐스   2.8  3.8  2.7  2.5  2.8         2.4   \n",
       "239  0.039683  0.000000    흥국화재   2.6  2.3  2.8  2.5  2.5         2.2   \n",
       "\n",
       "            fi result  \n",
       "0     2.308304      A  \n",
       "1     0.664337      B  \n",
       "2     2.477649      A  \n",
       "3     7.220688      A  \n",
       "4     9.538798      A  \n",
       "..         ...    ...  \n",
       "235   1.564620      A  \n",
       "236   0.662624      A  \n",
       "237   0.793223      A  \n",
       "238   0.846391     B+  \n",
       "239  13.211184     B+  \n",
       "\n",
       "[240 rows x 18 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.merge(pd.merge(pd.merge(news_variable, job_variable), fi_variable),ESG)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#독립변수와 종속변수 분리\n",
    "\n",
    "x = df_train.drop(['Unnamed: 0','company','result'], axis=1)\n",
    "\n",
    "print(len(x))\n",
    "\n",
    "y = df_train['result']\n",
    "\n",
    "print(len(y))\n",
    "\n",
    "#ESG등급 라벨링\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(y)\n",
    "\n",
    "labels = le.classes_\n",
    "\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x,pd.DataFrame(y),df_train['company']],axis=1).to_excel('final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x,pd.DataFrame(y)],axis=1).to_excel('finalv1111.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected names:  Index(['Topic_0', 'Topic_1', 'Topic_2', 'Topic_3', 'Topic_4', 'Topic_5',\n",
      "       'Topic_6', 'Topic_7', 'star', 'up', 'wel', 'wl', 'cul', 'management',\n",
      "       'fi'],\n",
      "      dtype='object')\n",
      "Unselected names:  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# target(Price)와 가장 correlated 된 features 를 k개 고르기.\n",
    "\n",
    "## f_regresison, SelectKBest 불러오기.\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "x_count = 15\n",
    "\n",
    "## selctor 정의하기.\n",
    "selector = SelectKBest(score_func=f_classif, k=x_count)\n",
    "\n",
    "x_selected = pd.DataFrame(selector.fit_transform(x, y))\n",
    "\n",
    "## f_regresison, SelectKBest 불러오기.\n",
    "\n",
    "## selctor 정의하기.\n",
    "all_names = x.columns\n",
    "\n",
    "## selector.get_support()\n",
    "selected_mask = selector.get_support()\n",
    "\n",
    "## 선택된 특성(변수)들\n",
    "selected_names = all_names[selected_mask]\n",
    "\n",
    "## 선택되지 않은 특성(변수)들\n",
    "unselected_names = all_names[~selected_mask]\n",
    "\n",
    "print('Selected names: ', selected_names)\n",
    "print('Unselected names: ', unselected_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.concat([x,pd.DataFrame(y)],axis=1).to_excel('finalv15.xlsx')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train 데이터 세트와 test 데이터 세트를 구성한다.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_selected, y, test_size=0.3, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 = 0.3611111111111111049432 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3611111111111111"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import mglearn\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "SVM_model = SVC(kernel='rbf')\n",
    "\n",
    "SVM_model = BaggingClassifier(SVM_model, random_state = 42, n_estimators = 10)\n",
    "\n",
    "SVM_model.fit(x_train, y_train)\n",
    "\n",
    "print('정확도 = %.22f ' % SVM_model.score(x_test, y_test))\n",
    "\n",
    "SVM_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 = 0.4861111111111111049432 \n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 모델 생성\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators= 10, random_state = 42)\n",
    "\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "# 정확도 확인\n",
    "print('정확도 = %.22f ' % forest.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 2.3019 - accuracy: 0.2321\n",
      "Epoch 2/200\n",
      "84/84 [==============================] - 0s 861us/step - loss: 1.8028 - accuracy: 0.2738\n",
      "Epoch 3/200\n",
      "84/84 [==============================] - 0s 950us/step - loss: 1.9069 - accuracy: 0.2500\n",
      "Epoch 4/200\n",
      "84/84 [==============================] - 0s 997us/step - loss: 1.8582 - accuracy: 0.3036\n",
      "Epoch 5/200\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.6988 - accuracy: 0.3214\n",
      "Epoch 6/200\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.7791 - accuracy: 0.2619\n",
      "Epoch 7/200\n",
      "84/84 [==============================] - 0s 805us/step - loss: 1.6547 - accuracy: 0.3095\n",
      "Epoch 8/200\n",
      "84/84 [==============================] - 0s 840us/step - loss: 1.6783 - accuracy: 0.3095\n",
      "Epoch 9/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.6649 - accuracy: 0.3214\n",
      "Epoch 10/200\n",
      "84/84 [==============================] - 0s 927us/step - loss: 1.5434 - accuracy: 0.3631\n",
      "Epoch 11/200\n",
      "84/84 [==============================] - 0s 826us/step - loss: 1.5911 - accuracy: 0.2976\n",
      "Epoch 12/200\n",
      "84/84 [==============================] - 0s 821us/step - loss: 1.5805 - accuracy: 0.2917\n",
      "Epoch 13/200\n",
      "84/84 [==============================] - 0s 915us/step - loss: 1.6622 - accuracy: 0.3214\n",
      "Epoch 14/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.6493 - accuracy: 0.3274\n",
      "Epoch 15/200\n",
      "84/84 [==============================] - 0s 832us/step - loss: 1.5141 - accuracy: 0.3333\n",
      "Epoch 16/200\n",
      "84/84 [==============================] - 0s 845us/step - loss: 1.5407 - accuracy: 0.3274\n",
      "Epoch 17/200\n",
      "84/84 [==============================] - 0s 813us/step - loss: 1.6658 - accuracy: 0.3036\n",
      "Epoch 18/200\n",
      "84/84 [==============================] - 0s 860us/step - loss: 1.4954 - accuracy: 0.3631\n",
      "Epoch 19/200\n",
      "84/84 [==============================] - 0s 825us/step - loss: 1.5965 - accuracy: 0.3452\n",
      "Epoch 20/200\n",
      "84/84 [==============================] - 0s 838us/step - loss: 1.5506 - accuracy: 0.3393\n",
      "Epoch 21/200\n",
      "84/84 [==============================] - 0s 829us/step - loss: 1.5285 - accuracy: 0.3274\n",
      "Epoch 22/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.5288 - accuracy: 0.3214\n",
      "Epoch 23/200\n",
      "84/84 [==============================] - 0s 741us/step - loss: 1.5419 - accuracy: 0.3631\n",
      "Epoch 24/200\n",
      "84/84 [==============================] - 0s 813us/step - loss: 1.5044 - accuracy: 0.3631\n",
      "Epoch 25/200\n",
      "84/84 [==============================] - 0s 885us/step - loss: 1.6073 - accuracy: 0.3571\n",
      "Epoch 26/200\n",
      "84/84 [==============================] - 0s 767us/step - loss: 1.4824 - accuracy: 0.3810\n",
      "Epoch 27/200\n",
      "84/84 [==============================] - 0s 869us/step - loss: 1.5727 - accuracy: 0.3452\n",
      "Epoch 28/200\n",
      "84/84 [==============================] - 0s 785us/step - loss: 1.5349 - accuracy: 0.3393\n",
      "Epoch 29/200\n",
      "84/84 [==============================] - 0s 787us/step - loss: 1.4341 - accuracy: 0.3571\n",
      "Epoch 30/200\n",
      "84/84 [==============================] - 0s 918us/step - loss: 1.4268 - accuracy: 0.3571\n",
      "Epoch 31/200\n",
      "84/84 [==============================] - 0s 793us/step - loss: 1.4637 - accuracy: 0.3452\n",
      "Epoch 32/200\n",
      "84/84 [==============================] - 0s 758us/step - loss: 1.4802 - accuracy: 0.3393\n",
      "Epoch 33/200\n",
      "84/84 [==============================] - 0s 821us/step - loss: 1.4259 - accuracy: 0.3512\n",
      "Epoch 34/200\n",
      "84/84 [==============================] - 0s 905us/step - loss: 1.4885 - accuracy: 0.3393\n",
      "Epoch 35/200\n",
      "84/84 [==============================] - 0s 894us/step - loss: 1.4440 - accuracy: 0.3631\n",
      "Epoch 36/200\n",
      "84/84 [==============================] - 0s 878us/step - loss: 1.4296 - accuracy: 0.3333\n",
      "Epoch 37/200\n",
      "84/84 [==============================] - 0s 795us/step - loss: 1.4247 - accuracy: 0.3690\n",
      "Epoch 38/200\n",
      "84/84 [==============================] - 0s 923us/step - loss: 1.6601 - accuracy: 0.3690\n",
      "Epoch 39/200\n",
      "84/84 [==============================] - 0s 788us/step - loss: 1.4603 - accuracy: 0.3512\n",
      "Epoch 40/200\n",
      "84/84 [==============================] - 0s 812us/step - loss: 1.5202 - accuracy: 0.3333\n",
      "Epoch 41/200\n",
      "84/84 [==============================] - 0s 858us/step - loss: 1.4428 - accuracy: 0.3810\n",
      "Epoch 42/200\n",
      "84/84 [==============================] - 0s 821us/step - loss: 1.5070 - accuracy: 0.3393\n",
      "Epoch 43/200\n",
      "84/84 [==============================] - 0s 837us/step - loss: 1.4340 - accuracy: 0.3571\n",
      "Epoch 44/200\n",
      "84/84 [==============================] - 0s 834us/step - loss: 1.4354 - accuracy: 0.3690\n",
      "Epoch 45/200\n",
      "84/84 [==============================] - 0s 815us/step - loss: 1.4744 - accuracy: 0.3512\n",
      "Epoch 46/200\n",
      "84/84 [==============================] - 0s 806us/step - loss: 1.4005 - accuracy: 0.3571\n",
      "Epoch 47/200\n",
      "84/84 [==============================] - 0s 909us/step - loss: 1.4569 - accuracy: 0.3690\n",
      "Epoch 48/200\n",
      "84/84 [==============================] - 0s 873us/step - loss: 1.4892 - accuracy: 0.3571\n",
      "Epoch 49/200\n",
      "84/84 [==============================] - 0s 874us/step - loss: 1.3996 - accuracy: 0.3690\n",
      "Epoch 50/200\n",
      "84/84 [==============================] - 0s 838us/step - loss: 1.4455 - accuracy: 0.3631\n",
      "Epoch 51/200\n",
      "84/84 [==============================] - 0s 857us/step - loss: 1.4443 - accuracy: 0.3512\n",
      "Epoch 52/200\n",
      "84/84 [==============================] - 0s 830us/step - loss: 1.4076 - accuracy: 0.3631\n",
      "Epoch 53/200\n",
      "84/84 [==============================] - 0s 886us/step - loss: 1.4489 - accuracy: 0.3571\n",
      "Epoch 54/200\n",
      "84/84 [==============================] - 0s 829us/step - loss: 1.4659 - accuracy: 0.3393\n",
      "Epoch 55/200\n",
      "84/84 [==============================] - 0s 816us/step - loss: 1.4424 - accuracy: 0.3631\n",
      "Epoch 56/200\n",
      "84/84 [==============================] - 0s 826us/step - loss: 1.4098 - accuracy: 0.3631\n",
      "Epoch 57/200\n",
      "84/84 [==============================] - 0s 810us/step - loss: 1.4337 - accuracy: 0.3631\n",
      "Epoch 58/200\n",
      "84/84 [==============================] - 0s 766us/step - loss: 1.4690 - accuracy: 0.3690\n",
      "Epoch 59/200\n",
      "84/84 [==============================] - 0s 856us/step - loss: 1.4179 - accuracy: 0.3750\n",
      "Epoch 60/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.4770 - accuracy: 0.3690\n",
      "Epoch 61/200\n",
      "84/84 [==============================] - 0s 822us/step - loss: 1.4891 - accuracy: 0.3631\n",
      "Epoch 62/200\n",
      "84/84 [==============================] - 0s 783us/step - loss: 1.5131 - accuracy: 0.3393\n",
      "Epoch 63/200\n",
      "84/84 [==============================] - 0s 798us/step - loss: 1.4439 - accuracy: 0.3512\n",
      "Epoch 64/200\n",
      "84/84 [==============================] - 0s 754us/step - loss: 1.4099 - accuracy: 0.3631\n",
      "Epoch 65/200\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.5041 - accuracy: 0.3690\n",
      "Epoch 66/200\n",
      "84/84 [==============================] - 0s 800us/step - loss: 1.4349 - accuracy: 0.3631\n",
      "Epoch 67/200\n",
      "84/84 [==============================] - 0s 780us/step - loss: 1.4068 - accuracy: 0.3452\n",
      "Epoch 68/200\n",
      "84/84 [==============================] - 0s 783us/step - loss: 1.4264 - accuracy: 0.3631\n",
      "Epoch 69/200\n",
      "84/84 [==============================] - 0s 812us/step - loss: 1.4144 - accuracy: 0.3571\n",
      "Epoch 70/200\n",
      "84/84 [==============================] - 0s 796us/step - loss: 1.4704 - accuracy: 0.3452\n",
      "Epoch 71/200\n",
      "84/84 [==============================] - 0s 752us/step - loss: 1.4007 - accuracy: 0.3690\n",
      "Epoch 72/200\n",
      "84/84 [==============================] - 0s 834us/step - loss: 1.4056 - accuracy: 0.3571\n",
      "Epoch 73/200\n",
      "84/84 [==============================] - 0s 768us/step - loss: 1.4521 - accuracy: 0.3631\n",
      "Epoch 74/200\n",
      "84/84 [==============================] - 0s 791us/step - loss: 1.4544 - accuracy: 0.3631\n",
      "Epoch 75/200\n",
      "84/84 [==============================] - 0s 796us/step - loss: 1.4375 - accuracy: 0.3690\n",
      "Epoch 76/200\n",
      "84/84 [==============================] - 0s 797us/step - loss: 1.4146 - accuracy: 0.3571\n",
      "Epoch 77/200\n",
      "84/84 [==============================] - 0s 761us/step - loss: 1.4328 - accuracy: 0.3690\n",
      "Epoch 78/200\n",
      "84/84 [==============================] - 0s 762us/step - loss: 1.3982 - accuracy: 0.3690\n",
      "Epoch 79/200\n",
      "84/84 [==============================] - 0s 722us/step - loss: 1.4863 - accuracy: 0.3452\n",
      "Epoch 80/200\n",
      "84/84 [==============================] - 0s 727us/step - loss: 1.4396 - accuracy: 0.3571\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 792us/step - loss: 1.4168 - accuracy: 0.3571\n",
      "Epoch 82/200\n",
      "84/84 [==============================] - 0s 824us/step - loss: 1.4079 - accuracy: 0.3631\n",
      "Epoch 83/200\n",
      "84/84 [==============================] - 0s 801us/step - loss: 1.4219 - accuracy: 0.3571\n",
      "Epoch 84/200\n",
      "84/84 [==============================] - 0s 799us/step - loss: 1.4248 - accuracy: 0.3631\n",
      "Epoch 85/200\n",
      "84/84 [==============================] - 0s 821us/step - loss: 1.4423 - accuracy: 0.3631\n",
      "Epoch 86/200\n",
      "84/84 [==============================] - 0s 785us/step - loss: 1.4242 - accuracy: 0.3571\n",
      "Epoch 87/200\n",
      "84/84 [==============================] - 0s 780us/step - loss: 1.4059 - accuracy: 0.3571\n",
      "Epoch 88/200\n",
      "84/84 [==============================] - 0s 808us/step - loss: 1.4219 - accuracy: 0.3690\n",
      "Epoch 89/200\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.4365 - accuracy: 0.3631\n",
      "Epoch 90/200\n",
      "84/84 [==============================] - 0s 790us/step - loss: 1.4182 - accuracy: 0.3571\n",
      "Epoch 91/200\n",
      "84/84 [==============================] - 0s 780us/step - loss: 1.5739 - accuracy: 0.3690\n",
      "Epoch 92/200\n",
      "84/84 [==============================] - 0s 780us/step - loss: 1.4105 - accuracy: 0.3631\n",
      "Epoch 93/200\n",
      "84/84 [==============================] - 0s 785us/step - loss: 1.4105 - accuracy: 0.3631\n",
      "Epoch 94/200\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.4101 - accuracy: 0.3631\n",
      "Epoch 95/200\n",
      "84/84 [==============================] - 0s 945us/step - loss: 1.4218 - accuracy: 0.3631\n",
      "Epoch 96/200\n",
      "84/84 [==============================] - 0s 884us/step - loss: 1.3835 - accuracy: 0.3631\n",
      "Epoch 97/200\n",
      "84/84 [==============================] - 0s 960us/step - loss: 1.4495 - accuracy: 0.3452\n",
      "Epoch 98/200\n",
      "84/84 [==============================] - 0s 809us/step - loss: 1.4090 - accuracy: 0.3571\n",
      "Epoch 99/200\n",
      "84/84 [==============================] - 0s 873us/step - loss: 1.4080 - accuracy: 0.3690\n",
      "Epoch 100/200\n",
      "84/84 [==============================] - 0s 827us/step - loss: 1.4289 - accuracy: 0.3512\n",
      "Epoch 101/200\n",
      "84/84 [==============================] - 0s 866us/step - loss: 1.4177 - accuracy: 0.3571\n",
      "Epoch 102/200\n",
      "84/84 [==============================] - 0s 771us/step - loss: 1.4220 - accuracy: 0.3571\n",
      "Epoch 103/200\n",
      "84/84 [==============================] - 0s 797us/step - loss: 1.3997 - accuracy: 0.3631\n",
      "Epoch 104/200\n",
      "84/84 [==============================] - 0s 977us/step - loss: 1.4032 - accuracy: 0.3631\n",
      "Epoch 105/200\n",
      "84/84 [==============================] - 0s 946us/step - loss: 1.3843 - accuracy: 0.3631\n",
      "Epoch 106/200\n",
      "84/84 [==============================] - 0s 729us/step - loss: 1.3956 - accuracy: 0.3631\n",
      "Epoch 107/200\n",
      "84/84 [==============================] - 0s 724us/step - loss: 1.3943 - accuracy: 0.3690\n",
      "Epoch 108/200\n",
      "84/84 [==============================] - 0s 730us/step - loss: 1.4246 - accuracy: 0.3571\n",
      "Epoch 109/200\n",
      "84/84 [==============================] - 0s 760us/step - loss: 1.4302 - accuracy: 0.3631\n",
      "Epoch 110/200\n",
      "84/84 [==============================] - 0s 795us/step - loss: 1.4033 - accuracy: 0.3631\n",
      "Epoch 111/200\n",
      "84/84 [==============================] - 0s 794us/step - loss: 1.3743 - accuracy: 0.3571\n",
      "Epoch 112/200\n",
      "84/84 [==============================] - 0s 766us/step - loss: 1.4340 - accuracy: 0.3571\n",
      "Epoch 113/200\n",
      "84/84 [==============================] - 0s 857us/step - loss: 1.4124 - accuracy: 0.3631\n",
      "Epoch 114/200\n",
      "84/84 [==============================] - 0s 801us/step - loss: 1.3846 - accuracy: 0.3690\n",
      "Epoch 115/200\n",
      "84/84 [==============================] - 0s 799us/step - loss: 1.3778 - accuracy: 0.3631\n",
      "Epoch 116/200\n",
      "84/84 [==============================] - 0s 785us/step - loss: 1.4003 - accuracy: 0.3631\n",
      "Epoch 117/200\n",
      "84/84 [==============================] - 0s 808us/step - loss: 1.4030 - accuracy: 0.3631\n",
      "Epoch 118/200\n",
      "84/84 [==============================] - 0s 793us/step - loss: 1.4700 - accuracy: 0.3571\n",
      "Epoch 119/200\n",
      "84/84 [==============================] - 0s 755us/step - loss: 1.4343 - accuracy: 0.3631\n",
      "Epoch 120/200\n",
      "84/84 [==============================] - 0s 775us/step - loss: 1.3951 - accuracy: 0.3631\n",
      "Epoch 121/200\n",
      "84/84 [==============================] - 0s 815us/step - loss: 1.3852 - accuracy: 0.3631\n",
      "Epoch 122/200\n",
      "84/84 [==============================] - 0s 881us/step - loss: 1.3785 - accuracy: 0.3631\n",
      "Epoch 123/200\n",
      "84/84 [==============================] - 0s 795us/step - loss: 1.3891 - accuracy: 0.3631\n",
      "Epoch 124/200\n",
      "84/84 [==============================] - 0s 792us/step - loss: 1.3693 - accuracy: 0.3631\n",
      "Epoch 125/200\n",
      "84/84 [==============================] - 0s 825us/step - loss: 1.3647 - accuracy: 0.3631\n",
      "Epoch 126/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.3987 - accuracy: 0.3631\n",
      "Epoch 127/200\n",
      "84/84 [==============================] - 0s 741us/step - loss: 1.4199 - accuracy: 0.3571\n",
      "Epoch 128/200\n",
      "84/84 [==============================] - 0s 781us/step - loss: 1.3811 - accuracy: 0.3631\n",
      "Epoch 129/200\n",
      "84/84 [==============================] - 0s 778us/step - loss: 1.4014 - accuracy: 0.3571\n",
      "Epoch 130/200\n",
      "84/84 [==============================] - 0s 808us/step - loss: 1.3860 - accuracy: 0.3631\n",
      "Epoch 131/200\n",
      "84/84 [==============================] - 0s 838us/step - loss: 1.4034 - accuracy: 0.3571\n",
      "Epoch 132/200\n",
      "84/84 [==============================] - 0s 778us/step - loss: 1.3835 - accuracy: 0.3571\n",
      "Epoch 133/200\n",
      "84/84 [==============================] - 0s 727us/step - loss: 1.3683 - accuracy: 0.3690\n",
      "Epoch 134/200\n",
      "84/84 [==============================] - 0s 702us/step - loss: 1.3927 - accuracy: 0.3750\n",
      "Epoch 135/200\n",
      "84/84 [==============================] - 0s 705us/step - loss: 1.3848 - accuracy: 0.3690\n",
      "Epoch 136/200\n",
      "84/84 [==============================] - 0s 805us/step - loss: 1.3984 - accuracy: 0.3750\n",
      "Epoch 137/200\n",
      "84/84 [==============================] - 0s 756us/step - loss: 1.4156 - accuracy: 0.3869\n",
      "Epoch 138/200\n",
      "84/84 [==============================] - 0s 773us/step - loss: 1.4105 - accuracy: 0.3631\n",
      "Epoch 139/200\n",
      "84/84 [==============================] - 0s 786us/step - loss: 1.3760 - accuracy: 0.3690\n",
      "Epoch 140/200\n",
      "84/84 [==============================] - 0s 783us/step - loss: 1.4129 - accuracy: 0.3810\n",
      "Epoch 141/200\n",
      "84/84 [==============================] - 0s 812us/step - loss: 1.3739 - accuracy: 0.3571\n",
      "Epoch 142/200\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.4108 - accuracy: 0.3333\n",
      "Epoch 143/200\n",
      "84/84 [==============================] - 0s 762us/step - loss: 1.4392 - accuracy: 0.3690\n",
      "Epoch 144/200\n",
      "84/84 [==============================] - 0s 787us/step - loss: 1.3935 - accuracy: 0.3512\n",
      "Epoch 145/200\n",
      "84/84 [==============================] - 0s 893us/step - loss: 1.3757 - accuracy: 0.3512\n",
      "Epoch 146/200\n",
      "84/84 [==============================] - 0s 857us/step - loss: 1.4111 - accuracy: 0.3869\n",
      "Epoch 147/200\n",
      "84/84 [==============================] - 0s 771us/step - loss: 1.3829 - accuracy: 0.3869\n",
      "Epoch 148/200\n",
      "84/84 [==============================] - 0s 784us/step - loss: 1.3648 - accuracy: 0.3929\n",
      "Epoch 149/200\n",
      "84/84 [==============================] - 0s 870us/step - loss: 1.3676 - accuracy: 0.3810\n",
      "Epoch 150/200\n",
      "84/84 [==============================] - 0s 778us/step - loss: 1.3537 - accuracy: 0.3750\n",
      "Epoch 151/200\n",
      "84/84 [==============================] - 0s 797us/step - loss: 1.4457 - accuracy: 0.3810\n",
      "Epoch 152/200\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.3727 - accuracy: 0.3929\n",
      "Epoch 153/200\n",
      "84/84 [==============================] - 0s 787us/step - loss: 1.3557 - accuracy: 0.4048\n",
      "Epoch 154/200\n",
      "84/84 [==============================] - 0s 771us/step - loss: 1.3870 - accuracy: 0.3690\n",
      "Epoch 155/200\n",
      "84/84 [==============================] - 0s 799us/step - loss: 1.3833 - accuracy: 0.3988\n",
      "Epoch 156/200\n",
      "84/84 [==============================] - 0s 812us/step - loss: 1.3737 - accuracy: 0.3929\n",
      "Epoch 157/200\n",
      "84/84 [==============================] - 0s 787us/step - loss: 1.3571 - accuracy: 0.3512\n",
      "Epoch 158/200\n",
      "84/84 [==============================] - 0s 829us/step - loss: 1.4616 - accuracy: 0.3988\n",
      "Epoch 159/200\n",
      "84/84 [==============================] - 0s 791us/step - loss: 1.3696 - accuracy: 0.3571\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 779us/step - loss: 1.3689 - accuracy: 0.3690\n",
      "Epoch 161/200\n",
      "84/84 [==============================] - 0s 758us/step - loss: 1.3683 - accuracy: 0.3690\n",
      "Epoch 162/200\n",
      "84/84 [==============================] - 0s 737us/step - loss: 1.3643 - accuracy: 0.3929\n",
      "Epoch 163/200\n",
      "84/84 [==============================] - 0s 709us/step - loss: 1.3420 - accuracy: 0.3810\n",
      "Epoch 164/200\n",
      "84/84 [==============================] - 0s 713us/step - loss: 1.3297 - accuracy: 0.4048\n",
      "Epoch 165/200\n",
      "84/84 [==============================] - 0s 792us/step - loss: 1.3582 - accuracy: 0.3571\n",
      "Epoch 166/200\n",
      "84/84 [==============================] - 0s 727us/step - loss: 1.3337 - accuracy: 0.3750\n",
      "Epoch 167/200\n",
      "84/84 [==============================] - 0s 776us/step - loss: 1.3376 - accuracy: 0.3571\n",
      "Epoch 168/200\n",
      "84/84 [==============================] - 0s 810us/step - loss: 1.3639 - accuracy: 0.3631\n",
      "Epoch 169/200\n",
      "84/84 [==============================] - 0s 831us/step - loss: 1.3560 - accuracy: 0.3929\n",
      "Epoch 170/200\n",
      "84/84 [==============================] - 0s 765us/step - loss: 1.3437 - accuracy: 0.3750\n",
      "Epoch 171/200\n",
      "84/84 [==============================] - 0s 770us/step - loss: 1.4029 - accuracy: 0.3274\n",
      "Epoch 172/200\n",
      "84/84 [==============================] - 0s 751us/step - loss: 1.3445 - accuracy: 0.3869\n",
      "Epoch 173/200\n",
      "84/84 [==============================] - 0s 991us/step - loss: 1.3839 - accuracy: 0.3750\n",
      "Epoch 174/200\n",
      "84/84 [==============================] - 0s 927us/step - loss: 1.3782 - accuracy: 0.3750\n",
      "Epoch 175/200\n",
      "84/84 [==============================] - 0s 822us/step - loss: 1.3667 - accuracy: 0.3988\n",
      "Epoch 176/200\n",
      "84/84 [==============================] - 0s 818us/step - loss: 1.3859 - accuracy: 0.3929\n",
      "Epoch 177/200\n",
      "84/84 [==============================] - 0s 822us/step - loss: 1.3546 - accuracy: 0.3810\n",
      "Epoch 178/200\n",
      "84/84 [==============================] - 0s 777us/step - loss: 1.3375 - accuracy: 0.3750\n",
      "Epoch 179/200\n",
      "84/84 [==============================] - 0s 802us/step - loss: 1.3648 - accuracy: 0.3929\n",
      "Epoch 180/200\n",
      "84/84 [==============================] - 0s 828us/step - loss: 1.3636 - accuracy: 0.3929\n",
      "Epoch 181/200\n",
      "84/84 [==============================] - 0s 838us/step - loss: 1.4214 - accuracy: 0.3750\n",
      "Epoch 182/200\n",
      "84/84 [==============================] - 0s 866us/step - loss: 1.3797 - accuracy: 0.3631\n",
      "Epoch 183/200\n",
      "84/84 [==============================] - 0s 836us/step - loss: 1.3128 - accuracy: 0.4405\n",
      "Epoch 184/200\n",
      "84/84 [==============================] - 0s 874us/step - loss: 1.3339 - accuracy: 0.3988\n",
      "Epoch 185/200\n",
      "84/84 [==============================] - 0s 860us/step - loss: 1.3560 - accuracy: 0.3988\n",
      "Epoch 186/200\n",
      "84/84 [==============================] - 0s 750us/step - loss: 1.3330 - accuracy: 0.3810\n",
      "Epoch 187/200\n",
      "84/84 [==============================] - 0s 804us/step - loss: 1.3419 - accuracy: 0.4107\n",
      "Epoch 188/200\n",
      "84/84 [==============================] - 0s 818us/step - loss: 1.3044 - accuracy: 0.3929\n",
      "Epoch 189/200\n",
      "84/84 [==============================] - 0s 857us/step - loss: 1.3769 - accuracy: 0.3631\n",
      "Epoch 190/200\n",
      "84/84 [==============================] - 0s 876us/step - loss: 1.3471 - accuracy: 0.3988\n",
      "Epoch 191/200\n",
      "84/84 [==============================] - 0s 764us/step - loss: 1.3294 - accuracy: 0.4048\n",
      "Epoch 192/200\n",
      "84/84 [==============================] - 0s 724us/step - loss: 1.3542 - accuracy: 0.4286\n",
      "Epoch 193/200\n",
      "84/84 [==============================] - 0s 879us/step - loss: 1.3818 - accuracy: 0.3512\n",
      "Epoch 194/200\n",
      "84/84 [==============================] - 0s 759us/step - loss: 1.3410 - accuracy: 0.3869\n",
      "Epoch 195/200\n",
      "84/84 [==============================] - 0s 788us/step - loss: 1.4003 - accuracy: 0.3631\n",
      "Epoch 196/200\n",
      "84/84 [==============================] - 0s 747us/step - loss: 1.4020 - accuracy: 0.3810\n",
      "Epoch 197/200\n",
      "84/84 [==============================] - 0s 787us/step - loss: 1.3610 - accuracy: 0.3988\n",
      "Epoch 198/200\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.3535 - accuracy: 0.3869\n",
      "Epoch 199/200\n",
      "84/84 [==============================] - 0s 781us/step - loss: 1.3444 - accuracy: 0.3512\n",
      "Epoch 200/200\n",
      "84/84 [==============================] - 0s 798us/step - loss: 1.3281 - accuracy: 0.3869\n",
      "36/36 [==============================] - 0s 728us/step - loss: 1.3003 - accuracy: 0.4722\n",
      "정확도: 0.4722222089767456\n"
     ]
    }
   ],
   "source": [
    "#DNN (은닉층 2개)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "#1. One-hot incoding, DNN의 경우 층화추출\n",
    "\n",
    "y_train_DNN = to_categorical(y_train)\n",
    "y_test_DNN = to_categorical(y_test)\n",
    "\n",
    "# 2. 모델 구성\n",
    "model = Sequential()\n",
    "\n",
    "#은닉층 1\n",
    "model.add(Dense(256, input_dim = x_count, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 2\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 3\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 4\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 5\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# 4. 모델 학습\n",
    "DNN_model = model.fit(x_train, y_train_DNN, epochs = 200, batch_size = 2)\n",
    "\n",
    "# 5. 모델 평가 \n",
    "score = model.evaluate(x_test, y_test_DNN, batch_size=2)\n",
    "\n",
    "print('정확도:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>RF</th>\n",
       "      <th>DNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SVM        RF       DNN\n",
       "0  0.361111  0.486111  0.472222"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame([SVM_model.score(x_test, y_test), forest.score(x_test, y_test),score[1]]).T\n",
    "\n",
    "result.columns = ['SVM','RF','DNN']\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimi_visualization(algorithm_name, x_values, train_score, test_score, xlabel, filename):\n",
    "    # 하이퍼파라미터 조정에 따른 학습 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(x_values, train_score, linestyle = '-', label = 'train score')\n",
    "    # 하이퍼파라미터 조정에 따른 테스트 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(x_values, test_score, linestyle = '--', label = 'test score')\n",
    "    plt.ylabel('Accuracy(%)') # y축 라벨\n",
    "    plt.xlabel(xlabel) # x축 라벨\n",
    "    plt.legend() # 범례표시\n",
    "    plt.savefig(algorithm_name + '_' + filename + '.png') # 시각화한 그래프는 로컬에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimi_estimator(algorithm, algorithm_name, x_train, y_train, x_test, y_test, n_estimator_min, n_estimator_max):\n",
    "    train_score = []; test_score =[]\n",
    "    para_n_tree = [n_tree*1 for n_tree in range(n_estimator_min, n_estimator_max)]\n",
    "\n",
    "    for v_n_estimators in para_n_tree:\n",
    "        model = RandomForestClassifier(n_estimators = v_n_estimators, random_state=42,n_jobs = -1)\n",
    "        model.fit(x_train, y_train)\n",
    "        train_score.append(model.score(x_train, y_train))\n",
    "        test_score.append(model.score(x_test, y_test))\n",
    "\n",
    "    # 트리 개수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'n_estimators': para_n_tree, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 트리 개수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_n_tree, train_score, test_score, \"The number of estimator\", \"n_estimator\")\n",
    "    print(round(df_score_n, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimi_maxdepth (algorithm, algorithm_name, x_train, y_train, x_test, y_test, depth_min, depth_max, n_estimator):\n",
    "    train_score = []; test_score = []\n",
    "    para_depth = [depth for depth in range(depth_min, depth_max)]\n",
    "\n",
    "    for v_max_depth in para_depth:\n",
    "        model = RandomForestClassifier(max_depth = v_max_depth, n_estimators = n_estimator,random_state=42,n_jobs = -1)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        train_score.append(model.score(x_train, y_train))\n",
    "        test_score.append(model.score(x_test, y_test))\n",
    "\n",
    "    # 최대 깊이에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'depth': para_depth, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 최대 깊이에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_depth, train_score, test_score, \"The number of depth\", \"n_depth\")\n",
    "    print(round(df_score_n, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'RFC'\n",
    "algorithm_name = 'rfc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_estimators  TrainScore  TestScore\n",
      "0              1      0.7976     0.2778\n",
      "1              2      0.7619     0.3750\n",
      "2              3      0.9048     0.3333\n",
      "3              4      0.9167     0.4028\n",
      "4              5      0.9286     0.3611\n",
      "..           ...         ...        ...\n",
      "94            95      1.0000     0.5694\n",
      "95            96      1.0000     0.5556\n",
      "96            97      1.0000     0.5833\n",
      "97            98      1.0000     0.5556\n",
      "98            99      1.0000     0.5556\n",
      "\n",
      "[99 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimator_min = 1\n",
    "n_estimator_max = 100\n",
    "optimi_estimator(algorithm, algorithm_name, \n",
    "                 x_train, y_train, x_test, y_test, \n",
    "                 n_estimator_min, n_estimator_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    depth  TrainScore  TestScore\n",
      "0       1      0.4405     0.3889\n",
      "1       2      0.5357     0.4306\n",
      "2       3      0.6667     0.5139\n",
      "3       4      0.7202     0.4444\n",
      "4       5      0.8690     0.4722\n",
      "..    ...         ...        ...\n",
      "94     95      1.0000     0.5833\n",
      "95     96      1.0000     0.5833\n",
      "96     97      1.0000     0.5833\n",
      "97     98      1.0000     0.5833\n",
      "98     99      1.0000     0.5833\n",
      "\n",
      "[99 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "depth_min = 1\n",
    "depth_max = 100\n",
    "optimi_maxdepth(algorithm, algorithm_name, \n",
    "                x_train, y_train, x_test, y_test, \n",
    "                depth_min, depth_max, n_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_depth = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 = 0.5972222222222222098864 \n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 모델 생성\n",
    "\n",
    "forest_after_hyper = RandomForestClassifier(n_estimators= n_estimator, max_depth = n_depth, random_state = 42,n_jobs = -1)\n",
    "\n",
    "forest_after_hyper.fit(x_train, y_train)\n",
    "\n",
    "# 정확도 확인\n",
    "print('정확도 = %.22f ' % forest_after_hyper.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESG_Predict_model.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(forest, 'ESG_Predict_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final = pd.DataFrame([SVM_model.score(x_test, y_test), forest.score(x_test, y_test),\n",
    "                       score[1],forest_after_hyper.score(x_test, y_test)]).T\n",
    "\n",
    "result_final.columns = ['SVM','RF','DNN','RF-H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>RF</th>\n",
       "      <th>DNN</th>\n",
       "      <th>RF-H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.597222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SVM        RF       DNN      RF-H\n",
       "0  0.361111  0.486111  0.472222  0.597222"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
