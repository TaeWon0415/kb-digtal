{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ESG_labeling(x):\n",
    "    \n",
    "    if x == 0:\n",
    "        x = 'A+'\n",
    "    \n",
    "    elif x ==  1:\n",
    "        x = 'A'\n",
    "        \n",
    "    elif x == 2:\n",
    "        x = 'B+'\n",
    "    \n",
    "    elif x == 3:\n",
    "        x = 'B'\n",
    "        \n",
    "    elif x == 4:\n",
    "        x = 'C'\n",
    "        \n",
    "    elif x == 5:\n",
    "        x = 'D'\n",
    "        \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>0.280724</td>\n",
       "      <td>0.103535</td>\n",
       "      <td>0.048822</td>\n",
       "      <td>0.042298</td>\n",
       "      <td>0.126684</td>\n",
       "      <td>0.236742</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>BGF리테일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.067251</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102339</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>BNK금융지주</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>BYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>CJ CGV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.100976</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>0.300113</td>\n",
       "      <td>0.067755</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>0.089152</td>\n",
       "      <td>CJ대한통운</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>255</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>효성화학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>휠라홀딩스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>257</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>휴비스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>휴켐스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.033730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>흥국화재</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Topic_0   Topic_1   Topic_2   Topic_3   Topic_4   Topic_5  \\\n",
       "0             0  0.039983  0.280724  0.103535  0.048822  0.042298  0.126684   \n",
       "1             1  0.236842  0.067251  0.210526  0.315789  0.000000  0.102339   \n",
       "2             2  0.000000  0.000000  0.625000  0.000000  0.000000  0.250000   \n",
       "3             3  0.125000  0.239583  0.218750  0.177083  0.000000  0.114583   \n",
       "4             4  0.100976  0.111486  0.071321  0.239865  0.300113  0.067755   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "255         255  0.444444  0.203704  0.000000  0.166667  0.000000  0.148148   \n",
       "256         256  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "257         257  0.058824  0.147059  0.117647  0.176471  0.058824  0.382353   \n",
       "258         258  0.000000  0.500000  0.000000  0.166667  0.000000  0.000000   \n",
       "259         259  0.077381  0.033730  0.500000  0.019841  0.025794  0.303571   \n",
       "\n",
       "      Topic_6   Topic_7  company  \n",
       "0    0.236742  0.121212   BGF리테일  \n",
       "1    0.035088  0.032164  BNK금융지주  \n",
       "2    0.125000  0.000000      BYC  \n",
       "3    0.062500  0.062500   CJ CGV  \n",
       "4    0.019332  0.089152   CJ대한통운  \n",
       "..        ...       ...      ...  \n",
       "255  0.037037  0.000000     효성화학  \n",
       "256  1.000000  0.000000    휠라홀딩스  \n",
       "257  0.000000  0.058824      휴비스  \n",
       "258  0.333333  0.000000      휴켐스  \n",
       "259  0.039683  0.000000     흥국화재  \n",
       "\n",
       "[260 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#사회 부문 예측\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "news_data = pd.read_csv('topic_variable.csv')\n",
    "\n",
    "#유의적인 변수만을 변수로 선택함\n",
    "\n",
    "#news_variable = news_data[['company','Topic_2','Topic_7','Topic_3']] \n",
    "\n",
    "#전체 변수 선택 시\n",
    "news_variable = news_data.drop(['date','합계'],axis = 1)\n",
    "\n",
    "news_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>star</th>\n",
       "      <th>up</th>\n",
       "      <th>wel</th>\n",
       "      <th>wl</th>\n",
       "      <th>cul</th>\n",
       "      <th>management</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BYC</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CJ CGV</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CJ씨푸드</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>휴켐스</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>흥국화재</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>한전기술</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>현대중공업지주</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>종근당홀딩스</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  star   up  wel   wl  cul  management\n",
       "0     BGF리테일   3.0  3.0  2.8  2.7  2.8         2.5\n",
       "1        BYC   2.3  1.8  3.3  2.3  1.9         1.8\n",
       "2     CJ CGV   3.5  3.6  3.0  3.3  3.1         2.9\n",
       "3     CJ대한통운   2.8  2.9  2.2  2.6  2.9         2.4\n",
       "4      CJ씨푸드   3.1  3.3  2.7  2.9  2.8         2.6\n",
       "..       ...   ...  ...  ...  ...  ...         ...\n",
       "244      휴켐스   2.8  3.8  2.7  2.5  2.8         2.4\n",
       "245     흥국화재   2.6  2.3  2.8  2.5  2.5         2.2\n",
       "246     한전기술   3.9  3.9  4.3  4.0  3.7         3.0\n",
       "247  현대중공업지주   2.9  2.9  3.1  2.6  2.9         2.2\n",
       "248   종근당홀딩스   2.9  3.4  2.4  2.2  2.9         2.1\n",
       "\n",
       "[249 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data = pd.read_csv('job_all_data.csv',encoding = 'cp949')\n",
    "\n",
    "job_variable = job_data.iloc[0:,1:7]\n",
    "\n",
    "job_variable = pd.concat([job_data['회사명'],job_variable],axis=1)\n",
    "\n",
    "job_variable.columns = ['company', 'star', 'up', 'wel', 'wl','cul','management']\n",
    "\n",
    "job_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>fi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>2.308304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BYC</td>\n",
       "      <td>0.664337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CJ CGV</td>\n",
       "      <td>2.477649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>7.220688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CJ씨푸드</td>\n",
       "      <td>0.135332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>현대에너지솔루션</td>\n",
       "      <td>0.459174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>휴켐스</td>\n",
       "      <td>0.846391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>한전기술</td>\n",
       "      <td>0.699244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>현대중공업지주</td>\n",
       "      <td>7.727859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>종근당홀딩스</td>\n",
       "      <td>0.393472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      company        fi\n",
       "0      BGF리테일  2.308304\n",
       "1         BYC  0.664337\n",
       "2      CJ CGV  2.477649\n",
       "3      CJ대한통운  7.220688\n",
       "4       CJ씨푸드  0.135332\n",
       "..        ...       ...\n",
       "244  현대에너지솔루션  0.459174\n",
       "245       휴켐스  0.846391\n",
       "246      한전기술  0.699244\n",
       "247   현대중공업지주  7.727859\n",
       "248    종근당홀딩스  0.393472\n",
       "\n",
       "[249 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_variable = pd.read_csv('fi_all_data.csv',encoding = 'cp949')\n",
    "fi_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK홀딩스</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BGF</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNK금융지주</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>효성첨단소재</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>효성티앤씨</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>효성화학</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>휠라홀딩스</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>휴비스</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>763 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     company result\n",
       "0     AJ네트웍스      B\n",
       "1      AK홀딩스     B+\n",
       "2        BGF      A\n",
       "3     BGF리테일      A\n",
       "4    BNK금융지주     A+\n",
       "..       ...    ...\n",
       "758   효성첨단소재      A\n",
       "759    효성티앤씨      A\n",
       "760     효성화학      A\n",
       "761    휠라홀딩스      A\n",
       "762      휴비스      A\n",
       "\n",
       "[763 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ESG 등급\n",
    "\n",
    "ESG = pd.read_csv('ESG_rating.csv', encoding = 'cp949')\n",
    "\n",
    "ESG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>company</th>\n",
       "      <th>star</th>\n",
       "      <th>up</th>\n",
       "      <th>wel</th>\n",
       "      <th>wl</th>\n",
       "      <th>cul</th>\n",
       "      <th>management</th>\n",
       "      <th>fi</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>0.280724</td>\n",
       "      <td>0.103535</td>\n",
       "      <td>0.048822</td>\n",
       "      <td>0.042298</td>\n",
       "      <td>0.126684</td>\n",
       "      <td>0.236742</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.308304</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>BYC</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.664337</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.239583</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>CJ CGV</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.477649</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.100976</td>\n",
       "      <td>0.111486</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>0.300113</td>\n",
       "      <td>0.067755</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>0.089152</td>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.220688</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.056026</td>\n",
       "      <td>0.180791</td>\n",
       "      <td>0.165254</td>\n",
       "      <td>0.054614</td>\n",
       "      <td>0.075330</td>\n",
       "      <td>0.078311</td>\n",
       "      <td>0.193817</td>\n",
       "      <td>0.195857</td>\n",
       "      <td>CJ제일제당</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>9.538798</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>255</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>효성화학</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.564620</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>휠라홀딩스</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.662624</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>257</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>휴비스</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.793223</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>휴켐스</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.846391</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>259</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.033730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>흥국화재</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>13.211184</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Topic_0   Topic_1   Topic_2   Topic_3   Topic_4   Topic_5  \\\n",
       "0             0  0.039983  0.280724  0.103535  0.048822  0.042298  0.126684   \n",
       "1             2  0.000000  0.000000  0.625000  0.000000  0.000000  0.250000   \n",
       "2             3  0.125000  0.239583  0.218750  0.177083  0.000000  0.114583   \n",
       "3             4  0.100976  0.111486  0.071321  0.239865  0.300113  0.067755   \n",
       "4             5  0.056026  0.180791  0.165254  0.054614  0.075330  0.078311   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "235         255  0.444444  0.203704  0.000000  0.166667  0.000000  0.148148   \n",
       "236         256  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "237         257  0.058824  0.147059  0.117647  0.176471  0.058824  0.382353   \n",
       "238         258  0.000000  0.500000  0.000000  0.166667  0.000000  0.000000   \n",
       "239         259  0.077381  0.033730  0.500000  0.019841  0.025794  0.303571   \n",
       "\n",
       "      Topic_6   Topic_7 company  star   up  wel   wl  cul  management  \\\n",
       "0    0.236742  0.121212  BGF리테일   3.0  3.0  2.8  2.7  2.8         2.5   \n",
       "1    0.125000  0.000000     BYC   2.3  1.8  3.3  2.3  1.9         1.8   \n",
       "2    0.062500  0.062500  CJ CGV   3.5  3.6  3.0  3.3  3.1         2.9   \n",
       "3    0.019332  0.089152  CJ대한통운   2.8  2.9  2.2  2.6  2.9         2.4   \n",
       "4    0.193817  0.195857  CJ제일제당   2.9  3.0  2.6  3.0  3.0         2.5   \n",
       "..        ...       ...     ...   ...  ...  ...  ...  ...         ...   \n",
       "235  0.037037  0.000000    효성화학   2.3  1.9  2.8  2.4  2.5         1.7   \n",
       "236  1.000000  0.000000   휠라홀딩스   2.8  2.8  2.9  2.4  2.9         2.3   \n",
       "237  0.000000  0.058824     휴비스   3.1  3.4  2.9  2.8  3.2         2.5   \n",
       "238  0.333333  0.000000     휴켐스   2.8  3.8  2.7  2.5  2.8         2.4   \n",
       "239  0.039683  0.000000    흥국화재   2.6  2.3  2.8  2.5  2.5         2.2   \n",
       "\n",
       "            fi result  \n",
       "0     2.308304      A  \n",
       "1     0.664337      B  \n",
       "2     2.477649      A  \n",
       "3     7.220688      A  \n",
       "4     9.538798      A  \n",
       "..         ...    ...  \n",
       "235   1.564620      A  \n",
       "236   0.662624      A  \n",
       "237   0.793223      A  \n",
       "238   0.846391     B+  \n",
       "239  13.211184     B+  \n",
       "\n",
       "[240 rows x 18 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.merge(pd.merge(pd.merge(news_variable, job_variable), fi_variable),ESG)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#독립변수와 종속변수 분리\n",
    "\n",
    "x = df_train.drop(['Unnamed: 0','company','result'], axis=1)\n",
    "\n",
    "print(len(x))\n",
    "\n",
    "y = df_train['result']\n",
    "\n",
    "print(len(y))\n",
    "\n",
    "#ESG등급 라벨링\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(y)\n",
    "\n",
    "labels = le.classes_\n",
    "\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x,pd.DataFrame(y),df_train['company']],axis=1).to_excel('final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x,pd.DataFrame(y)],axis=1).to_excel('finalv1111.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected names:  Index(['Topic_0', 'Topic_1', 'Topic_2', 'Topic_3', 'Topic_4', 'Topic_5',\n",
      "       'Topic_6', 'Topic_7', 'star', 'up', 'wel', 'wl', 'cul', 'management',\n",
      "       'fi'],\n",
      "      dtype='object')\n",
      "Unselected names:  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# target(Price)와 가장 correlated 된 features 를 k개 고르기.\n",
    "\n",
    "## f_regresison, SelectKBest 불러오기.\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "x_count = 15\n",
    "\n",
    "## selctor 정의하기.\n",
    "selector = SelectKBest(score_func=f_classif, k=x_count)\n",
    "\n",
    "x_selected = pd.DataFrame(selector.fit_transform(x, y))\n",
    "\n",
    "## f_regresison, SelectKBest 불러오기.\n",
    "\n",
    "## selctor 정의하기.\n",
    "all_names = x.columns\n",
    "\n",
    "## selector.get_support()\n",
    "selected_mask = selector.get_support()\n",
    "\n",
    "## 선택된 특성(변수)들\n",
    "selected_names = all_names[selected_mask]\n",
    "\n",
    "## 선택되지 않은 특성(변수)들\n",
    "unselected_names = all_names[~selected_mask]\n",
    "\n",
    "print('Selected names: ', selected_names)\n",
    "print('Unselected names: ', unselected_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.concat([x,pd.DataFrame(y)],axis=1).to_excel('finalv15.xlsx')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train 데이터 세트와 test 데이터 세트를 구성한다.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_selected, y, test_size=0.3, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 = 0.3611111111111111049432 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3611111111111111"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import mglearn\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "SVM_model = SVC(kernel='rbf')\n",
    "\n",
    "SVM_model = BaggingClassifier(SVM_model, random_state = 42, n_estimators = 10)\n",
    "\n",
    "SVM_model.fit(x_train, y_train)\n",
    "\n",
    "print('정확도 = %.22f ' % SVM_model.score(x_test, y_test))\n",
    "\n",
    "SVM_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 = 0.4861111111111111049432 \n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 모델 생성\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators= 10, random_state = 42)\n",
    "\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "# 정확도 확인\n",
    "print('정확도 = %.22f ' % forest.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 2.3019 - accuracy: 0.2321\n",
      "Epoch 2/200\n",
      "84/84 [==============================] - 0s 861us/step - loss: 1.8028 - accuracy: 0.2738\n",
      "Epoch 3/200\n",
      "84/84 [==============================] - 0s 950us/step - loss: 1.9069 - accuracy: 0.2500\n",
      "Epoch 4/200\n",
      "84/84 [==============================] - 0s 997us/step - loss: 1.8582 - accuracy: 0.3036\n",
      "Epoch 5/200\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.6988 - accuracy: 0.3214\n",
      "Epoch 6/200\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.7791 - accuracy: 0.2619\n",
      "Epoch 7/200\n",
      "84/84 [==============================] - 0s 805us/step - loss: 1.6547 - accuracy: 0.3095\n",
      "Epoch 8/200\n",
      "84/84 [==============================] - 0s 840us/step - loss: 1.6783 - accuracy: 0.3095\n",
      "Epoch 9/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.6649 - accuracy: 0.3214\n",
      "Epoch 10/200\n",
      "84/84 [==============================] - 0s 927us/step - loss: 1.5434 - accuracy: 0.3631\n",
      "Epoch 11/200\n",
      "84/84 [==============================] - 0s 826us/step - loss: 1.5911 - accuracy: 0.2976\n",
      "Epoch 12/200\n",
      "84/84 [==============================] - 0s 821us/step - loss: 1.5805 - accuracy: 0.2917\n",
      "Epoch 13/200\n",
      "84/84 [==============================] - 0s 915us/step - loss: 1.6622 - accuracy: 0.3214\n",
      "Epoch 14/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.6493 - accuracy: 0.3274\n",
      "Epoch 15/200\n",
      "84/84 [==============================] - 0s 832us/step - loss: 1.5141 - accuracy: 0.3333\n",
      "Epoch 16/200\n",
      "84/84 [==============================] - 0s 845us/step - loss: 1.5407 - accuracy: 0.3274\n",
      "Epoch 17/200\n",
      "84/84 [==============================] - 0s 813us/step - loss: 1.6658 - accuracy: 0.3036\n",
      "Epoch 18/200\n",
      "84/84 [==============================] - 0s 860us/step - loss: 1.4954 - accuracy: 0.3631\n",
      "Epoch 19/200\n",
      "84/84 [==============================] - 0s 825us/step - loss: 1.5965 - accuracy: 0.3452\n",
      "Epoch 20/200\n",
      "84/84 [==============================] - 0s 838us/step - loss: 1.5506 - accuracy: 0.3393\n",
      "Epoch 21/200\n",
      "84/84 [==============================] - 0s 829us/step - loss: 1.5285 - accuracy: 0.3274\n",
      "Epoch 22/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.5288 - accuracy: 0.3214\n",
      "Epoch 23/200\n",
      "84/84 [==============================] - 0s 741us/step - loss: 1.5419 - accuracy: 0.3631\n",
      "Epoch 24/200\n",
      "84/84 [==============================] - 0s 813us/step - loss: 1.5044 - accuracy: 0.3631\n",
      "Epoch 25/200\n",
      "84/84 [==============================] - 0s 885us/step - loss: 1.6073 - accuracy: 0.3571\n",
      "Epoch 26/200\n",
      "84/84 [==============================] - 0s 767us/step - loss: 1.4824 - accuracy: 0.3810\n",
      "Epoch 27/200\n",
      "84/84 [==============================] - 0s 869us/step - loss: 1.5727 - accuracy: 0.3452\n",
      "Epoch 28/200\n",
      "84/84 [==============================] - 0s 785us/step - loss: 1.5349 - accuracy: 0.3393\n",
      "Epoch 29/200\n",
      "84/84 [==============================] - 0s 787us/step - loss: 1.4341 - accuracy: 0.3571\n",
      "Epoch 30/200\n",
      "84/84 [==============================] - 0s 918us/step - loss: 1.4268 - accuracy: 0.3571\n",
      "Epoch 31/200\n",
      "84/84 [==============================] - 0s 793us/step - loss: 1.4637 - accuracy: 0.3452\n",
      "Epoch 32/200\n",
      "84/84 [==============================] - 0s 758us/step - loss: 1.4802 - accuracy: 0.3393\n",
      "Epoch 33/200\n",
      "84/84 [==============================] - 0s 821us/step - loss: 1.4259 - accuracy: 0.3512\n",
      "Epoch 34/200\n",
      "84/84 [==============================] - 0s 905us/step - loss: 1.4885 - accuracy: 0.3393\n",
      "Epoch 35/200\n",
      "84/84 [==============================] - 0s 894us/step - loss: 1.4440 - accuracy: 0.3631\n",
      "Epoch 36/200\n",
      "84/84 [==============================] - 0s 878us/step - loss: 1.4296 - accuracy: 0.3333\n",
      "Epoch 37/200\n",
      "84/84 [==============================] - 0s 795us/step - loss: 1.4247 - accuracy: 0.3690\n",
      "Epoch 38/200\n",
      "84/84 [==============================] - 0s 923us/step - loss: 1.6601 - accuracy: 0.3690\n",
      "Epoch 39/200\n",
      "84/84 [==============================] - 0s 788us/step - loss: 1.4603 - accuracy: 0.3512\n",
      "Epoch 40/200\n",
      "84/84 [==============================] - 0s 812us/step - loss: 1.5202 - accuracy: 0.3333\n",
      "Epoch 41/200\n",
      "84/84 [==============================] - 0s 858us/step - loss: 1.4428 - accuracy: 0.3810\n",
      "Epoch 42/200\n",
      "84/84 [==============================] - 0s 821us/step - loss: 1.5070 - accuracy: 0.3393\n",
      "Epoch 43/200\n",
      "84/84 [==============================] - 0s 837us/step - loss: 1.4340 - accuracy: 0.3571\n",
      "Epoch 44/200\n",
      "84/84 [==============================] - 0s 834us/step - loss: 1.4354 - accuracy: 0.3690\n",
      "Epoch 45/200\n",
      "84/84 [==============================] - 0s 815us/step - loss: 1.4744 - accuracy: 0.3512\n",
      "Epoch 46/200\n",
      "84/84 [==============================] - 0s 806us/step - loss: 1.4005 - accuracy: 0.3571\n",
      "Epoch 47/200\n",
      "84/84 [==============================] - 0s 909us/step - loss: 1.4569 - accuracy: 0.3690\n",
      "Epoch 48/200\n",
      "84/84 [==============================] - 0s 873us/step - loss: 1.4892 - accuracy: 0.3571\n",
      "Epoch 49/200\n",
      "84/84 [==============================] - 0s 874us/step - loss: 1.3996 - accuracy: 0.3690\n",
      "Epoch 50/200\n",
      "84/84 [==============================] - 0s 838us/step - loss: 1.4455 - accuracy: 0.3631\n",
      "Epoch 51/200\n",
      "84/84 [==============================] - 0s 857us/step - loss: 1.4443 - accuracy: 0.3512\n",
      "Epoch 52/200\n",
      "84/84 [==============================] - 0s 830us/step - loss: 1.4076 - accuracy: 0.3631\n",
      "Epoch 53/200\n",
      "84/84 [==============================] - 0s 886us/step - loss: 1.4489 - accuracy: 0.3571\n",
      "Epoch 54/200\n",
      "84/84 [==============================] - 0s 829us/step - loss: 1.4659 - accuracy: 0.3393\n",
      "Epoch 55/200\n",
      "84/84 [==============================] - 0s 816us/step - loss: 1.4424 - accuracy: 0.3631\n",
      "Epoch 56/200\n",
      "84/84 [==============================] - 0s 826us/step - loss: 1.4098 - accuracy: 0.3631\n",
      "Epoch 57/200\n",
      "84/84 [==============================] - 0s 810us/step - loss: 1.4337 - accuracy: 0.3631\n",
      "Epoch 58/200\n",
      "84/84 [==============================] - 0s 766us/step - loss: 1.4690 - accuracy: 0.3690\n",
      "Epoch 59/200\n",
      "84/84 [==============================] - 0s 856us/step - loss: 1.4179 - accuracy: 0.3750\n",
      "Epoch 60/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.4770 - accuracy: 0.3690\n",
      "Epoch 61/200\n",
      "84/84 [==============================] - 0s 822us/step - loss: 1.4891 - accuracy: 0.3631\n",
      "Epoch 62/200\n",
      "84/84 [==============================] - 0s 783us/step - loss: 1.5131 - accuracy: 0.3393\n",
      "Epoch 63/200\n",
      "84/84 [==============================] - 0s 798us/step - loss: 1.4439 - accuracy: 0.3512\n",
      "Epoch 64/200\n",
      "84/84 [==============================] - 0s 754us/step - loss: 1.4099 - accuracy: 0.3631\n",
      "Epoch 65/200\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.5041 - accuracy: 0.3690\n",
      "Epoch 66/200\n",
      "84/84 [==============================] - 0s 800us/step - loss: 1.4349 - accuracy: 0.3631\n",
      "Epoch 67/200\n",
      "84/84 [==============================] - 0s 780us/step - loss: 1.4068 - accuracy: 0.3452\n",
      "Epoch 68/200\n",
      "84/84 [==============================] - 0s 783us/step - loss: 1.4264 - accuracy: 0.3631\n",
      "Epoch 69/200\n",
      "84/84 [==============================] - 0s 812us/step - loss: 1.4144 - accuracy: 0.3571\n",
      "Epoch 70/200\n",
      "84/84 [==============================] - 0s 796us/step - loss: 1.4704 - accuracy: 0.3452\n",
      "Epoch 71/200\n",
      "84/84 [==============================] - 0s 752us/step - loss: 1.4007 - accuracy: 0.3690\n",
      "Epoch 72/200\n",
      "84/84 [==============================] - 0s 834us/step - loss: 1.4056 - accuracy: 0.3571\n",
      "Epoch 73/200\n",
      "84/84 [==============================] - 0s 768us/step - loss: 1.4521 - accuracy: 0.3631\n",
      "Epoch 74/200\n",
      "84/84 [==============================] - 0s 791us/step - loss: 1.4544 - accuracy: 0.3631\n",
      "Epoch 75/200\n",
      "84/84 [==============================] - 0s 796us/step - loss: 1.4375 - accuracy: 0.3690\n",
      "Epoch 76/200\n",
      "84/84 [==============================] - 0s 797us/step - loss: 1.4146 - accuracy: 0.3571\n",
      "Epoch 77/200\n",
      "84/84 [==============================] - 0s 761us/step - loss: 1.4328 - accuracy: 0.3690\n",
      "Epoch 78/200\n",
      "84/84 [==============================] - 0s 762us/step - loss: 1.3982 - accuracy: 0.3690\n",
      "Epoch 79/200\n",
      "84/84 [==============================] - 0s 722us/step - loss: 1.4863 - accuracy: 0.3452\n",
      "Epoch 80/200\n",
      "84/84 [==============================] - 0s 727us/step - loss: 1.4396 - accuracy: 0.3571\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 792us/step - loss: 1.4168 - accuracy: 0.3571\n",
      "Epoch 82/200\n",
      "84/84 [==============================] - 0s 824us/step - loss: 1.4079 - accuracy: 0.3631\n",
      "Epoch 83/200\n",
      "84/84 [==============================] - 0s 801us/step - loss: 1.4219 - accuracy: 0.3571\n",
      "Epoch 84/200\n",
      "84/84 [==============================] - 0s 799us/step - loss: 1.4248 - accuracy: 0.3631\n",
      "Epoch 85/200\n",
      "84/84 [==============================] - 0s 821us/step - loss: 1.4423 - accuracy: 0.3631\n",
      "Epoch 86/200\n",
      "84/84 [==============================] - 0s 785us/step - loss: 1.4242 - accuracy: 0.3571\n",
      "Epoch 87/200\n",
      "84/84 [==============================] - 0s 780us/step - loss: 1.4059 - accuracy: 0.3571\n",
      "Epoch 88/200\n",
      "84/84 [==============================] - 0s 808us/step - loss: 1.4219 - accuracy: 0.3690\n",
      "Epoch 89/200\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.4365 - accuracy: 0.3631\n",
      "Epoch 90/200\n",
      "84/84 [==============================] - 0s 790us/step - loss: 1.4182 - accuracy: 0.3571\n",
      "Epoch 91/200\n",
      "84/84 [==============================] - 0s 780us/step - loss: 1.5739 - accuracy: 0.3690\n",
      "Epoch 92/200\n",
      "84/84 [==============================] - 0s 780us/step - loss: 1.4105 - accuracy: 0.3631\n",
      "Epoch 93/200\n",
      "84/84 [==============================] - 0s 785us/step - loss: 1.4105 - accuracy: 0.3631\n",
      "Epoch 94/200\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.4101 - accuracy: 0.3631\n",
      "Epoch 95/200\n",
      "84/84 [==============================] - 0s 945us/step - loss: 1.4218 - accuracy: 0.3631\n",
      "Epoch 96/200\n",
      "84/84 [==============================] - 0s 884us/step - loss: 1.3835 - accuracy: 0.3631\n",
      "Epoch 97/200\n",
      "84/84 [==============================] - 0s 960us/step - loss: 1.4495 - accuracy: 0.3452\n",
      "Epoch 98/200\n",
      "84/84 [==============================] - 0s 809us/step - loss: 1.4090 - accuracy: 0.3571\n",
      "Epoch 99/200\n",
      "84/84 [==============================] - 0s 873us/step - loss: 1.4080 - accuracy: 0.3690\n",
      "Epoch 100/200\n",
      "84/84 [==============================] - 0s 827us/step - loss: 1.4289 - accuracy: 0.3512\n",
      "Epoch 101/200\n",
      "84/84 [==============================] - 0s 866us/step - loss: 1.4177 - accuracy: 0.3571\n",
      "Epoch 102/200\n",
      "84/84 [==============================] - 0s 771us/step - loss: 1.4220 - accuracy: 0.3571\n",
      "Epoch 103/200\n",
      "84/84 [==============================] - 0s 797us/step - loss: 1.3997 - accuracy: 0.3631\n",
      "Epoch 104/200\n",
      "84/84 [==============================] - 0s 977us/step - loss: 1.4032 - accuracy: 0.3631\n",
      "Epoch 105/200\n",
      "84/84 [==============================] - 0s 946us/step - loss: 1.3843 - accuracy: 0.3631\n",
      "Epoch 106/200\n",
      "84/84 [==============================] - 0s 729us/step - loss: 1.3956 - accuracy: 0.3631\n",
      "Epoch 107/200\n",
      "84/84 [==============================] - 0s 724us/step - loss: 1.3943 - accuracy: 0.3690\n",
      "Epoch 108/200\n",
      "84/84 [==============================] - 0s 730us/step - loss: 1.4246 - accuracy: 0.3571\n",
      "Epoch 109/200\n",
      "84/84 [==============================] - 0s 760us/step - loss: 1.4302 - accuracy: 0.3631\n",
      "Epoch 110/200\n",
      "84/84 [==============================] - 0s 795us/step - loss: 1.4033 - accuracy: 0.3631\n",
      "Epoch 111/200\n",
      "84/84 [==============================] - 0s 794us/step - loss: 1.3743 - accuracy: 0.3571\n",
      "Epoch 112/200\n",
      "84/84 [==============================] - 0s 766us/step - loss: 1.4340 - accuracy: 0.3571\n",
      "Epoch 113/200\n",
      "84/84 [==============================] - 0s 857us/step - loss: 1.4124 - accuracy: 0.3631\n",
      "Epoch 114/200\n",
      "84/84 [==============================] - 0s 801us/step - loss: 1.3846 - accuracy: 0.3690\n",
      "Epoch 115/200\n",
      "84/84 [==============================] - 0s 799us/step - loss: 1.3778 - accuracy: 0.3631\n",
      "Epoch 116/200\n",
      "84/84 [==============================] - 0s 785us/step - loss: 1.4003 - accuracy: 0.3631\n",
      "Epoch 117/200\n",
      "84/84 [==============================] - 0s 808us/step - loss: 1.4030 - accuracy: 0.3631\n",
      "Epoch 118/200\n",
      "84/84 [==============================] - 0s 793us/step - loss: 1.4700 - accuracy: 0.3571\n",
      "Epoch 119/200\n",
      "84/84 [==============================] - 0s 755us/step - loss: 1.4343 - accuracy: 0.3631\n",
      "Epoch 120/200\n",
      "84/84 [==============================] - 0s 775us/step - loss: 1.3951 - accuracy: 0.3631\n",
      "Epoch 121/200\n",
      "84/84 [==============================] - 0s 815us/step - loss: 1.3852 - accuracy: 0.3631\n",
      "Epoch 122/200\n",
      "84/84 [==============================] - 0s 881us/step - loss: 1.3785 - accuracy: 0.3631\n",
      "Epoch 123/200\n",
      "84/84 [==============================] - 0s 795us/step - loss: 1.3891 - accuracy: 0.3631\n",
      "Epoch 124/200\n",
      "84/84 [==============================] - 0s 792us/step - loss: 1.3693 - accuracy: 0.3631\n",
      "Epoch 125/200\n",
      "84/84 [==============================] - 0s 825us/step - loss: 1.3647 - accuracy: 0.3631\n",
      "Epoch 126/200\n",
      "84/84 [==============================] - 0s 823us/step - loss: 1.3987 - accuracy: 0.3631\n",
      "Epoch 127/200\n",
      "84/84 [==============================] - 0s 741us/step - loss: 1.4199 - accuracy: 0.3571\n",
      "Epoch 128/200\n",
      "84/84 [==============================] - 0s 781us/step - loss: 1.3811 - accuracy: 0.3631\n",
      "Epoch 129/200\n",
      "84/84 [==============================] - 0s 778us/step - loss: 1.4014 - accuracy: 0.3571\n",
      "Epoch 130/200\n",
      "84/84 [==============================] - 0s 808us/step - loss: 1.3860 - accuracy: 0.3631\n",
      "Epoch 131/200\n",
      "84/84 [==============================] - 0s 838us/step - loss: 1.4034 - accuracy: 0.3571\n",
      "Epoch 132/200\n",
      "84/84 [==============================] - 0s 778us/step - loss: 1.3835 - accuracy: 0.3571\n",
      "Epoch 133/200\n",
      "84/84 [==============================] - 0s 727us/step - loss: 1.3683 - accuracy: 0.3690\n",
      "Epoch 134/200\n",
      "84/84 [==============================] - 0s 702us/step - loss: 1.3927 - accuracy: 0.3750\n",
      "Epoch 135/200\n",
      "84/84 [==============================] - 0s 705us/step - loss: 1.3848 - accuracy: 0.3690\n",
      "Epoch 136/200\n",
      "84/84 [==============================] - 0s 805us/step - loss: 1.3984 - accuracy: 0.3750\n",
      "Epoch 137/200\n",
      "84/84 [==============================] - 0s 756us/step - loss: 1.4156 - accuracy: 0.3869\n",
      "Epoch 138/200\n",
      "84/84 [==============================] - 0s 773us/step - loss: 1.4105 - accuracy: 0.3631\n",
      "Epoch 139/200\n",
      "84/84 [==============================] - 0s 786us/step - loss: 1.3760 - accuracy: 0.3690\n",
      "Epoch 140/200\n",
      "84/84 [==============================] - 0s 783us/step - loss: 1.4129 - accuracy: 0.3810\n",
      "Epoch 141/200\n",
      "84/84 [==============================] - 0s 812us/step - loss: 1.3739 - accuracy: 0.3571\n",
      "Epoch 142/200\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.4108 - accuracy: 0.3333\n",
      "Epoch 143/200\n",
      "84/84 [==============================] - 0s 762us/step - loss: 1.4392 - accuracy: 0.3690\n",
      "Epoch 144/200\n",
      "84/84 [==============================] - 0s 787us/step - loss: 1.3935 - accuracy: 0.3512\n",
      "Epoch 145/200\n",
      "84/84 [==============================] - 0s 893us/step - loss: 1.3757 - accuracy: 0.3512\n",
      "Epoch 146/200\n",
      "84/84 [==============================] - 0s 857us/step - loss: 1.4111 - accuracy: 0.3869\n",
      "Epoch 147/200\n",
      "84/84 [==============================] - 0s 771us/step - loss: 1.3829 - accuracy: 0.3869\n",
      "Epoch 148/200\n",
      "84/84 [==============================] - 0s 784us/step - loss: 1.3648 - accuracy: 0.3929\n",
      "Epoch 149/200\n",
      "84/84 [==============================] - 0s 870us/step - loss: 1.3676 - accuracy: 0.3810\n",
      "Epoch 150/200\n",
      "84/84 [==============================] - 0s 778us/step - loss: 1.3537 - accuracy: 0.3750\n",
      "Epoch 151/200\n",
      "84/84 [==============================] - 0s 797us/step - loss: 1.4457 - accuracy: 0.3810\n",
      "Epoch 152/200\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.3727 - accuracy: 0.3929\n",
      "Epoch 153/200\n",
      "84/84 [==============================] - 0s 787us/step - loss: 1.3557 - accuracy: 0.4048\n",
      "Epoch 154/200\n",
      "84/84 [==============================] - 0s 771us/step - loss: 1.3870 - accuracy: 0.3690\n",
      "Epoch 155/200\n",
      "84/84 [==============================] - 0s 799us/step - loss: 1.3833 - accuracy: 0.3988\n",
      "Epoch 156/200\n",
      "84/84 [==============================] - 0s 812us/step - loss: 1.3737 - accuracy: 0.3929\n",
      "Epoch 157/200\n",
      "67/84 [======================>.......] - ETA: 0s - loss: 1.3798 - accuracy: 0.3433"
     ]
    }
   ],
   "source": [
    "#DNN (은닉층 2개)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "#1. One-hot incoding, DNN의 경우 층화추출\n",
    "\n",
    "y_train_DNN = to_categorical(y_train)\n",
    "y_test_DNN = to_categorical(y_test)\n",
    "\n",
    "# 2. 모델 구성\n",
    "model = Sequential()\n",
    "\n",
    "#은닉층 1\n",
    "model.add(Dense(256, input_dim = x_count, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 2\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 3\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 4\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 5\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# 4. 모델 학습\n",
    "DNN_model = model.fit(x_train, y_train_DNN, epochs = 200, batch_size = 2)\n",
    "\n",
    "# 5. 모델 평가 \n",
    "score = model.evaluate(x_test, y_test_DNN, batch_size=2)\n",
    "\n",
    "print('정확도:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame([SVM_model.score(x_test, y_test), forest.score(x_test, y_test),score[1]]).T\n",
    "\n",
    "result.columns = ['SVM','RF','DNN']\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimi_visualization(algorithm_name, x_values, train_score, test_score, xlabel, filename):\n",
    "    # 하이퍼파라미터 조정에 따른 학습 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(x_values, train_score, linestyle = '-', label = 'train score')\n",
    "    # 하이퍼파라미터 조정에 따른 테스트 데이터셋 기반 모델 성능 추이 시각화\n",
    "    plt.plot(x_values, test_score, linestyle = '--', label = 'test score')\n",
    "    plt.ylabel('Accuracy(%)') # y축 라벨\n",
    "    plt.xlabel(xlabel) # x축 라벨\n",
    "    plt.legend() # 범례표시\n",
    "    plt.savefig(algorithm_name + '_' + filename + '.png') # 시각화한 그래프는 로컬에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimi_estimator(algorithm, algorithm_name, x_train, y_train, x_test, y_test, n_estimator_min, n_estimator_max):\n",
    "    train_score = []; test_score =[]\n",
    "    para_n_tree = [n_tree*1 for n_tree in range(n_estimator_min, n_estimator_max)]\n",
    "\n",
    "    for v_n_estimators in para_n_tree:\n",
    "        model = RandomForestClassifier(n_estimators = v_n_estimators, random_state=42,n_jobs = -1)\n",
    "        model.fit(x_train, y_train)\n",
    "        train_score.append(model.score(x_train, y_train))\n",
    "        test_score.append(model.score(x_test, y_test))\n",
    "\n",
    "    # 트리 개수에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'n_estimators': para_n_tree, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 트리 개수에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_n_tree, train_score, test_score, \"The number of estimator\", \"n_estimator\")\n",
    "    print(round(df_score_n, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimi_maxdepth (algorithm, algorithm_name, x_train, y_train, x_test, y_test, depth_min, depth_max, n_estimator):\n",
    "    train_score = []; test_score = []\n",
    "    para_depth = [depth for depth in range(depth_min, depth_max)]\n",
    "\n",
    "    for v_max_depth in para_depth:\n",
    "        model = RandomForestClassifier(max_depth = v_max_depth, n_estimators = n_estimator,random_state=42,n_jobs = -1)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        train_score.append(model.score(x_train, y_train))\n",
    "        test_score.append(model.score(x_test, y_test))\n",
    "\n",
    "    # 최대 깊이에 따른 모델 성능 저장\n",
    "    df_score_n = pd.DataFrame({'depth': para_depth, 'TrainScore': train_score, 'TestScore': test_score})\n",
    "    # 최대 깊이에 따른 모델 성능 추이 시각화 함수 호출\n",
    "    optimi_visualization(algorithm_name, para_depth, train_score, test_score, \"The number of depth\", \"n_depth\")\n",
    "    print(round(df_score_n, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'RFC'\n",
    "algorithm_name = 'rfc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator_min = 1\n",
    "n_estimator_max = 100\n",
    "optimi_estimator(algorithm, algorithm_name, \n",
    "                 x_train, y_train, x_test, y_test, \n",
    "                 n_estimator_min, n_estimator_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_min = 1\n",
    "depth_max = 100\n",
    "optimi_maxdepth(algorithm, algorithm_name, \n",
    "                x_train, y_train, x_test, y_test, \n",
    "                depth_min, depth_max, n_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_depth = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤포레스트\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 모델 생성\n",
    "\n",
    "forest_after_hyper = RandomForestClassifier(n_estimators= n_estimator, max_depth = n_depth, random_state = 42,n_jobs = -1)\n",
    "\n",
    "forest_after_hyper.fit(x_train, y_train)\n",
    "\n",
    "# 정확도 확인\n",
    "print('정확도 = %.22f ' % forest_after_hyper.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(forest, 'ESG_Predict_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final = pd.DataFrame([SVM_model.score(x_test, y_test), forest.score(x_test, y_test),\n",
    "                       score[1],forest_after_hyper.score(x_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
