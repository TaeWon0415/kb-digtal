{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ESG_labeling(x):\n",
    "    \n",
    "    if x == 0:\n",
    "        x = 'A+'\n",
    "    \n",
    "    elif x ==  1:\n",
    "        x = 'A'\n",
    "        \n",
    "    elif x == 2:\n",
    "        x = 'B+'\n",
    "    \n",
    "    elif x == 3:\n",
    "        x = 'B'\n",
    "        \n",
    "    elif x == 4:\n",
    "        x = 'C'\n",
    "        \n",
    "    elif x == 5:\n",
    "        x = 'D'\n",
    "        \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.089724</td>\n",
       "      <td>0.246431</td>\n",
       "      <td>0.115787</td>\n",
       "      <td>0.061006</td>\n",
       "      <td>0.036272</td>\n",
       "      <td>0.118443</td>\n",
       "      <td>0.229333</td>\n",
       "      <td>0.103005</td>\n",
       "      <td>BGF리테일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.341814</td>\n",
       "      <td>0.089602</td>\n",
       "      <td>0.110251</td>\n",
       "      <td>0.188422</td>\n",
       "      <td>0.009956</td>\n",
       "      <td>0.195796</td>\n",
       "      <td>0.018805</td>\n",
       "      <td>0.045354</td>\n",
       "      <td>BNK금융지주</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.130663</td>\n",
       "      <td>0.120146</td>\n",
       "      <td>0.297330</td>\n",
       "      <td>0.218851</td>\n",
       "      <td>0.020631</td>\n",
       "      <td>0.099110</td>\n",
       "      <td>0.052994</td>\n",
       "      <td>0.060275</td>\n",
       "      <td>CJ CGV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.101813</td>\n",
       "      <td>0.128984</td>\n",
       "      <td>0.085411</td>\n",
       "      <td>0.197923</td>\n",
       "      <td>0.266612</td>\n",
       "      <td>0.110839</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.080431</td>\n",
       "      <td>CJ대한통운</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.106954</td>\n",
       "      <td>0.172334</td>\n",
       "      <td>0.177237</td>\n",
       "      <td>0.076137</td>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.071346</td>\n",
       "      <td>0.139952</td>\n",
       "      <td>0.184265</td>\n",
       "      <td>CJ제일제당</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>0.519108</td>\n",
       "      <td>0.152866</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.184713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>효성중공업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>0.694175</td>\n",
       "      <td>0.076052</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.085761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>효성첨단소재</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>0.685924</td>\n",
       "      <td>0.076681</td>\n",
       "      <td>0.024860</td>\n",
       "      <td>0.071078</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.079482</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>효성티앤씨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>0.786458</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>효성화학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>183</td>\n",
       "      <td>0.145674</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>0.484097</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.255089</td>\n",
       "      <td>0.035623</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>흥국화재</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Topic_0   Topic_1   Topic_2   Topic_3   Topic_4   Topic_5  \\\n",
       "0             0  0.089724  0.246431  0.115787  0.061006  0.036272  0.118443   \n",
       "1             1  0.341814  0.089602  0.110251  0.188422  0.009956  0.195796   \n",
       "2             2  0.130663  0.120146  0.297330  0.218851  0.020631  0.099110   \n",
       "3             3  0.101813  0.128984  0.085411  0.197923  0.266612  0.110839   \n",
       "4             4  0.106954  0.172334  0.177237  0.076137  0.071775  0.071346   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "179         179  0.519108  0.152866  0.022293  0.184713  0.000000  0.057325   \n",
       "180         180  0.694175  0.076052  0.009709  0.085761  0.000000  0.124595   \n",
       "181         181  0.685924  0.076681  0.024860  0.071078  0.005252  0.079482   \n",
       "182         182  0.786458  0.072917  0.010417  0.057292  0.000000  0.057292   \n",
       "183         183  0.145674  0.031807  0.484097  0.022265  0.015267  0.255089   \n",
       "\n",
       "      Topic_6   Topic_7  company  \n",
       "0    0.229333  0.103005   BGF리테일  \n",
       "1    0.018805  0.045354  BNK금융지주  \n",
       "2    0.052994  0.060275   CJ CGV  \n",
       "3    0.027988  0.080431   CJ대한통운  \n",
       "4    0.139952  0.184265   CJ제일제당  \n",
       "..        ...       ...      ...  \n",
       "179  0.012739  0.050955    효성중공업  \n",
       "180  0.009709  0.000000   효성첨단소재  \n",
       "181  0.017857  0.038866    효성티앤씨  \n",
       "182  0.010417  0.005208     효성화학  \n",
       "183  0.035623  0.010178     흥국화재  \n",
       "\n",
       "[184 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#사회 부문 예측\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "news_data = pd.read_csv('topic_variable.csv')\n",
    "\n",
    "#유의적인 변수만을 변수로 선택함\n",
    "\n",
    "#news_variable = news_data[['company','Topic_2','Topic_7','Topic_3']] \n",
    "\n",
    "#전체 변수 선택 시\n",
    "news_variable = news_data.drop(['date','합계'],axis = 1)\n",
    "\n",
    "news_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>star</th>\n",
       "      <th>up</th>\n",
       "      <th>wel</th>\n",
       "      <th>wl</th>\n",
       "      <th>cul</th>\n",
       "      <th>management</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BYC</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CJ CGV</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CJ씨푸드</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>효성티앤씨</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>효성화학</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>휠라홀딩스</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>휴비스</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>흥국화재</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company  star   up  wel   wl  cul  management\n",
       "0    BGF리테일   3.0  3.0  2.8  2.7  2.8         2.5\n",
       "1       BYC   2.3  1.8  3.3  2.3  1.9         1.8\n",
       "2    CJ CGV   3.5  3.6  3.0  3.3  3.1         2.9\n",
       "3    CJ대한통운   2.8  2.9  2.2  2.6  2.9         2.4\n",
       "4     CJ씨푸드   3.1  3.3  2.7  2.9  2.8         2.6\n",
       "..      ...   ...  ...  ...  ...  ...         ...\n",
       "220   효성티앤씨   2.5  2.2  2.8  2.3  2.6         1.9\n",
       "221    효성화학   2.3  1.9  2.8  2.4  2.5         1.7\n",
       "222   휠라홀딩스   2.8  2.8  2.9  2.4  2.9         2.3\n",
       "223     휴비스   3.1  3.4  2.9  2.8  3.2         2.5\n",
       "224    흥국화재   2.6  2.3  2.8  2.5  2.5         2.2\n",
       "\n",
       "[225 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data = pd.read_csv('job_all_data.csv',encoding = 'cp949')\n",
    "\n",
    "job_variable = job_data.iloc[0:,1:7]\n",
    "\n",
    "job_variable = pd.concat([job_data['회사명'],job_variable],axis=1)\n",
    "\n",
    "job_variable.columns = ['company', 'star', 'up', 'wel', 'wl','cul','management']\n",
    "\n",
    "job_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK홀딩스</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BGF</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNK금융지주</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>효성첨단소재</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>효성티앤씨</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>효성화학</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>휠라홀딩스</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>휴비스</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>763 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     company result\n",
       "0     AJ네트웍스      B\n",
       "1      AK홀딩스     B+\n",
       "2        BGF      A\n",
       "3     BGF리테일      A\n",
       "4    BNK금융지주     A+\n",
       "..       ...    ...\n",
       "758   효성첨단소재      A\n",
       "759    효성티앤씨      A\n",
       "760     효성화학      A\n",
       "761    휠라홀딩스      A\n",
       "762      휴비스      A\n",
       "\n",
       "[763 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ESG 등급\n",
    "\n",
    "ESG = pd.read_csv('ESG_rating.csv', encoding = 'cp949')\n",
    "\n",
    "ESG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic_0</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>Topic_6</th>\n",
       "      <th>Topic_7</th>\n",
       "      <th>company</th>\n",
       "      <th>star</th>\n",
       "      <th>up</th>\n",
       "      <th>wel</th>\n",
       "      <th>wl</th>\n",
       "      <th>cul</th>\n",
       "      <th>management</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.089724</td>\n",
       "      <td>0.246431</td>\n",
       "      <td>0.115787</td>\n",
       "      <td>0.061006</td>\n",
       "      <td>0.036272</td>\n",
       "      <td>0.118443</td>\n",
       "      <td>0.229333</td>\n",
       "      <td>0.103005</td>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.130663</td>\n",
       "      <td>0.120146</td>\n",
       "      <td>0.297330</td>\n",
       "      <td>0.218851</td>\n",
       "      <td>0.020631</td>\n",
       "      <td>0.099110</td>\n",
       "      <td>0.052994</td>\n",
       "      <td>0.060275</td>\n",
       "      <td>CJ CGV</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.101813</td>\n",
       "      <td>0.128984</td>\n",
       "      <td>0.085411</td>\n",
       "      <td>0.197923</td>\n",
       "      <td>0.266612</td>\n",
       "      <td>0.110839</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.080431</td>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.106954</td>\n",
       "      <td>0.172334</td>\n",
       "      <td>0.177237</td>\n",
       "      <td>0.076137</td>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.071346</td>\n",
       "      <td>0.139952</td>\n",
       "      <td>0.184265</td>\n",
       "      <td>CJ제일제당</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.385253</td>\n",
       "      <td>0.085138</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.033602</td>\n",
       "      <td>0.040975</td>\n",
       "      <td>0.211098</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>DB손해보험</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>179</td>\n",
       "      <td>0.519108</td>\n",
       "      <td>0.152866</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.184713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>효성중공업</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>180</td>\n",
       "      <td>0.694175</td>\n",
       "      <td>0.076052</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.085761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>효성첨단소재</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>181</td>\n",
       "      <td>0.685924</td>\n",
       "      <td>0.076681</td>\n",
       "      <td>0.024860</td>\n",
       "      <td>0.071078</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.079482</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>효성티앤씨</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>182</td>\n",
       "      <td>0.786458</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>효성화학</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>183</td>\n",
       "      <td>0.145674</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>0.484097</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.255089</td>\n",
       "      <td>0.035623</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>흥국화재</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Topic_0   Topic_1   Topic_2   Topic_3   Topic_4   Topic_5  \\\n",
       "0             0  0.089724  0.246431  0.115787  0.061006  0.036272  0.118443   \n",
       "1             2  0.130663  0.120146  0.297330  0.218851  0.020631  0.099110   \n",
       "2             3  0.101813  0.128984  0.085411  0.197923  0.266612  0.110839   \n",
       "3             4  0.106954  0.172334  0.177237  0.076137  0.071775  0.071346   \n",
       "4             5  0.184716  0.385253  0.085138  0.022542  0.033602  0.040975   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "159         179  0.519108  0.152866  0.022293  0.184713  0.000000  0.057325   \n",
       "160         180  0.694175  0.076052  0.009709  0.085761  0.000000  0.124595   \n",
       "161         181  0.685924  0.076681  0.024860  0.071078  0.005252  0.079482   \n",
       "162         182  0.786458  0.072917  0.010417  0.057292  0.000000  0.057292   \n",
       "163         183  0.145674  0.031807  0.484097  0.022265  0.015267  0.255089   \n",
       "\n",
       "      Topic_6   Topic_7 company  star   up  wel   wl  cul  management result  \n",
       "0    0.229333  0.103005  BGF리테일   3.0  3.0  2.8  2.7  2.8         2.5      A  \n",
       "1    0.052994  0.060275  CJ CGV   3.5  3.6  3.0  3.3  3.1         2.9      A  \n",
       "2    0.027988  0.080431  CJ대한통운   2.8  2.9  2.2  2.6  2.9         2.4      A  \n",
       "3    0.139952  0.184265  CJ제일제당   2.9  3.0  2.6  3.0  3.0         2.5      A  \n",
       "4    0.211098  0.036674  DB손해보험   3.0  3.4  2.5  2.5  3.0         2.6      A  \n",
       "..        ...       ...     ...   ...  ...  ...  ...  ...         ...    ...  \n",
       "159  0.012739  0.050955   효성중공업   2.7  2.7  2.7  2.7  2.8         2.0      A  \n",
       "160  0.009709  0.000000  효성첨단소재   2.3  2.4  2.1  1.9  2.5         1.8      A  \n",
       "161  0.017857  0.038866   효성티앤씨   2.5  2.2  2.8  2.3  2.6         1.9      A  \n",
       "162  0.010417  0.005208    효성화학   2.3  1.9  2.8  2.4  2.5         1.7      A  \n",
       "163  0.035623  0.010178    흥국화재   2.6  2.3  2.8  2.5  2.5         2.2     B+  \n",
       "\n",
       "[164 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.merge(pd.merge(news_variable, job_variable), ESG)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#독립변수와 종속변수 분리\n",
    "\n",
    "x = df_train.drop(['Unnamed: 0','company','result'], axis=1)\n",
    "\n",
    "print(len(x))\n",
    "\n",
    "y = df_train['result']\n",
    "\n",
    "print(len(y))\n",
    "\n",
    "#ESG등급 라벨링\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(y)\n",
    "\n",
    "labels = le.classes_\n",
    "\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x,pd.DataFrame(y),df_train['company']],axis=1).to_excel('finalv1111111.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x,pd.DataFrame(y)],axis=1).to_excel('finalv1111.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected names:  Index(['Topic_1', 'Topic_2', 'Topic_3', 'Topic_7', 'star', 'up', 'wel', 'wl',\n",
      "       'cul', 'management'],\n",
      "      dtype='object')\n",
      "Unselected names:  Index(['Topic_0', 'Topic_4', 'Topic_5', 'Topic_6'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# target(Price)와 가장 correlated 된 features 를 k개 고르기.\n",
    "\n",
    "## f_regresison, SelectKBest 불러오기.\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "x_count = 10\n",
    "\n",
    "## selctor 정의하기.\n",
    "selector = SelectKBest(score_func=f_classif, k=x_count)\n",
    "\n",
    "x_selected = pd.DataFrame(selector.fit_transform(x, y))\n",
    "\n",
    "## f_regresison, SelectKBest 불러오기.\n",
    "\n",
    "## selctor 정의하기.\n",
    "all_names = x.columns\n",
    "\n",
    "## selector.get_support()\n",
    "selected_mask = selector.get_support()\n",
    "\n",
    "## 선택된 특성(변수)들\n",
    "selected_names = all_names[selected_mask]\n",
    "\n",
    "## 선택되지 않은 특성(변수)들\n",
    "unselected_names = all_names[~selected_mask]\n",
    "\n",
    "print('Selected names: ', selected_names)\n",
    "print('Unselected names: ', unselected_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.concat([x,pd.DataFrame(y)],axis=1).to_excel('finalv15.xlsx')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train 데이터 세트와 test 데이터 세트를 구성한다.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_selected, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 = 0.52 \n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import mglearn\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 튜닝 : gamma와 C의 조합을 바꿔가면서 학습 데이터의 정확도가 최대인 조합을 찾는다.\n",
    "\n",
    "SVM_model = SVC(kernel='rbf')\n",
    "\n",
    "SVM_model = BaggingClassifier(SVM_model, random_state = 42, n_estimators = 100)\n",
    "\n",
    "SVM_model.fit(x_train, y_train)\n",
    "\n",
    "print('정확도 = %.2f ' % SVM_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 = 0.51 \n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 모델 생성\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators= 100 ,random_state = 42)\n",
    "\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "# 정확도 확인\n",
    "print('정확도 = %.2f ' % forest.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 0s 998us/step - loss: 2.1864 - accuracy: 0.2143\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.8320 - accuracy: 0.2597\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.7228 - accuracy: 0.2922\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6696 - accuracy: 0.3052\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6854 - accuracy: 0.2922\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6310 - accuracy: 0.3312\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6296 - accuracy: 0.2597\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.6482 - accuracy: 0.3182\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 0s 982us/step - loss: 1.5973 - accuracy: 0.2922\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.5872 - accuracy: 0.3247\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.5143 - accuracy: 0.3506\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 0s 893us/step - loss: 1.5541 - accuracy: 0.2857\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 0s 866us/step - loss: 1.5120 - accuracy: 0.2922\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 0s 855us/step - loss: 1.5070 - accuracy: 0.3442\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 0s 892us/step - loss: 1.5564 - accuracy: 0.3117\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 0s 952us/step - loss: 1.5275 - accuracy: 0.2922\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 0s 954us/step - loss: 1.5331 - accuracy: 0.3506\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 0s 936us/step - loss: 1.5270 - accuracy: 0.3247\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 0s 865us/step - loss: 1.5274 - accuracy: 0.3247\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 0s 824us/step - loss: 1.4691 - accuracy: 0.3377\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 0s 944us/step - loss: 1.5288 - accuracy: 0.3636\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 0s 1000us/step - loss: 1.5187 - accuracy: 0.3312\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 0s 939us/step - loss: 1.5302 - accuracy: 0.3442\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 0s 904us/step - loss: 1.4990 - accuracy: 0.3442\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.5067 - accuracy: 0.3442\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 0s 876us/step - loss: 1.4811 - accuracy: 0.3182\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 0s 964us/step - loss: 1.4785 - accuracy: 0.3442\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 0s 886us/step - loss: 1.4734 - accuracy: 0.3442\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 0s 880us/step - loss: 1.5215 - accuracy: 0.3052\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4719 - accuracy: 0.3312\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4525 - accuracy: 0.3442\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 0s 988us/step - loss: 1.4518 - accuracy: 0.3442\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 0s 963us/step - loss: 1.5198 - accuracy: 0.3377\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4697 - accuracy: 0.3052\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4469 - accuracy: 0.3312\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4466 - accuracy: 0.3506\n",
      "Epoch 37/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4888 - accuracy: 0.3182\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4670 - accuracy: 0.3312\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.5003 - accuracy: 0.3377\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4872 - accuracy: 0.3377\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4502 - accuracy: 0.3442\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4875 - accuracy: 0.3312\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4815 - accuracy: 0.3442\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4543 - accuracy: 0.3442\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4865 - accuracy: 0.3312\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4692 - accuracy: 0.3442\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4431 - accuracy: 0.3442\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4551 - accuracy: 0.3442\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 0s 985us/step - loss: 1.4733 - accuracy: 0.3442\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 0s 905us/step - loss: 1.4660 - accuracy: 0.3442\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 0s 924us/step - loss: 1.4797 - accuracy: 0.3442\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 0s 925us/step - loss: 1.4793 - accuracy: 0.3442\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 0s 840us/step - loss: 1.4479 - accuracy: 0.3442\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 0s 826us/step - loss: 1.4685 - accuracy: 0.3377\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 0s 808us/step - loss: 1.4887 - accuracy: 0.3442\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 0s 859us/step - loss: 1.4499 - accuracy: 0.3442\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 0s 879us/step - loss: 1.4505 - accuracy: 0.3442\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 0s 856us/step - loss: 1.4447 - accuracy: 0.3442\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 0s 937us/step - loss: 1.4486 - accuracy: 0.3442\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 0s 811us/step - loss: 1.4715 - accuracy: 0.3506\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 0s 911us/step - loss: 1.4903 - accuracy: 0.3377\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 0s 840us/step - loss: 1.4705 - accuracy: 0.3442\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 0s 924us/step - loss: 1.4553 - accuracy: 0.3442\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 0s 911us/step - loss: 1.4629 - accuracy: 0.3442\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 0s 962us/step - loss: 1.4474 - accuracy: 0.3442\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 0s 840us/step - loss: 1.4488 - accuracy: 0.3442\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 0s 900us/step - loss: 1.4617 - accuracy: 0.3442\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 0s 845us/step - loss: 1.4656 - accuracy: 0.3442\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 0s 898us/step - loss: 1.4549 - accuracy: 0.3442\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 0s 948us/step - loss: 1.4503 - accuracy: 0.3442\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 0s 924us/step - loss: 1.4765 - accuracy: 0.3377\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 0s 994us/step - loss: 1.4479 - accuracy: 0.3442\n",
      "Epoch 73/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4509 - accuracy: 0.3442\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 0s 989us/step - loss: 1.4476 - accuracy: 0.3442\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4568 - accuracy: 0.3506\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4612 - accuracy: 0.3442\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4657 - accuracy: 0.3442\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4530 - accuracy: 0.3442\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4669 - accuracy: 0.3442\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4558 - accuracy: 0.3377\n",
      "Epoch 81/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4395 - accuracy: 0.3442\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4381 - accuracy: 0.3442\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4522 - accuracy: 0.3442\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 0s 955us/step - loss: 1.4530 - accuracy: 0.3506\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 0s 977us/step - loss: 1.4630 - accuracy: 0.3442\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4533 - accuracy: 0.3442\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 0s 997us/step - loss: 1.4707 - accuracy: 0.3442\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4548 - accuracy: 0.3442\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4497 - accuracy: 0.3442\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 0s 914us/step - loss: 1.4497 - accuracy: 0.3442\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 0s 861us/step - loss: 1.4418 - accuracy: 0.3442\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 0s 866us/step - loss: 1.4538 - accuracy: 0.3442\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 0s 849us/step - loss: 1.4512 - accuracy: 0.3442\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 0s 807us/step - loss: 1.4502 - accuracy: 0.3442\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 0s 833us/step - loss: 1.4514 - accuracy: 0.3442\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 0s 859us/step - loss: 1.4469 - accuracy: 0.3442\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 0s 873us/step - loss: 1.4541 - accuracy: 0.3442\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 0s 873us/step - loss: 1.4507 - accuracy: 0.3442\n",
      "Epoch 99/200\n",
      "77/77 [==============================] - 0s 886us/step - loss: 1.4626 - accuracy: 0.3442\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 0s 878us/step - loss: 1.4458 - accuracy: 0.3442\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 0s 902us/step - loss: 1.4447 - accuracy: 0.3442\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 0s 928us/step - loss: 1.4575 - accuracy: 0.3377\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 0s 907us/step - loss: 1.4458 - accuracy: 0.3442\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 0s 948us/step - loss: 1.4516 - accuracy: 0.3442\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 0s 980us/step - loss: 1.4444 - accuracy: 0.3442\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 0s 940us/step - loss: 1.4535 - accuracy: 0.3442\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 0s 881us/step - loss: 1.4579 - accuracy: 0.3442\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 0s 887us/step - loss: 1.4352 - accuracy: 0.3442\n",
      "Epoch 109/200\n",
      "77/77 [==============================] - 0s 915us/step - loss: 1.4443 - accuracy: 0.3442\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 0s 959us/step - loss: 1.4442 - accuracy: 0.3442\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4428 - accuracy: 0.3442\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4570 - accuracy: 0.3377\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 0s 992us/step - loss: 1.4373 - accuracy: 0.3442\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4487 - accuracy: 0.3442\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4533 - accuracy: 0.3442\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 0s 952us/step - loss: 1.4526 - accuracy: 0.3442\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4493 - accuracy: 0.3442\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4552 - accuracy: 0.3442\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4402 - accuracy: 0.3442\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 0s 969us/step - loss: 1.4427 - accuracy: 0.3442\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 0s 974us/step - loss: 1.4510 - accuracy: 0.3442\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4604 - accuracy: 0.3442\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4576 - accuracy: 0.3442\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4397 - accuracy: 0.3442\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4380 - accuracy: 0.3442\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 0s 965us/step - loss: 1.4480 - accuracy: 0.3442\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 0s 959us/step - loss: 1.4519 - accuracy: 0.3442\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4454 - accuracy: 0.3442\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4413 - accuracy: 0.3442\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4565 - accuracy: 0.3442\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 0s 942us/step - loss: 1.4502 - accuracy: 0.3442\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 0s 880us/step - loss: 1.4482 - accuracy: 0.3442\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 0s 837us/step - loss: 1.4396 - accuracy: 0.3442\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 0s 830us/step - loss: 1.4473 - accuracy: 0.3442\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 0s 894us/step - loss: 1.4447 - accuracy: 0.3442\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 0s 939us/step - loss: 1.4482 - accuracy: 0.3442\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 0s 927us/step - loss: 1.4498 - accuracy: 0.3442\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 0s 852us/step - loss: 1.4330 - accuracy: 0.3442\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 0s 870us/step - loss: 1.4386 - accuracy: 0.3442\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4501 - accuracy: 0.3442\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4475 - accuracy: 0.3442\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4510 - accuracy: 0.3442\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 0s 977us/step - loss: 1.4427 - accuracy: 0.3442\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 0s 951us/step - loss: 1.4419 - accuracy: 0.3442\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 0s 924us/step - loss: 1.4467 - accuracy: 0.3442\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 0s 880us/step - loss: 1.4496 - accuracy: 0.3442\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 0s 935us/step - loss: 1.4391 - accuracy: 0.3442\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 0s 839us/step - loss: 1.4507 - accuracy: 0.3442\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4325 - accuracy: 0.3442\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 0s 854us/step - loss: 1.4635 - accuracy: 0.3506\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4495 - accuracy: 0.3442\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4532 - accuracy: 0.3442\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4457 - accuracy: 0.3442\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4482 - accuracy: 0.3442\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4519 - accuracy: 0.3442\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4497 - accuracy: 0.3442\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4444 - accuracy: 0.3442\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4394 - accuracy: 0.3442\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4409 - accuracy: 0.3442\n",
      "Epoch 160/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4395 - accuracy: 0.3442\n",
      "Epoch 161/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4438 - accuracy: 0.3442\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4491 - accuracy: 0.3442\n",
      "Epoch 163/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4471 - accuracy: 0.3442\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4498 - accuracy: 0.3442\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4497 - accuracy: 0.3442\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 0s 972us/step - loss: 1.4443 - accuracy: 0.3442\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 0s 913us/step - loss: 1.4488 - accuracy: 0.3442\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4378 - accuracy: 0.3442\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 0s 923us/step - loss: 1.4372 - accuracy: 0.3442\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 0s 914us/step - loss: 1.4475 - accuracy: 0.3442\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4547 - accuracy: 0.3442\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 0s 809us/step - loss: 1.4476 - accuracy: 0.3442\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 0s 844us/step - loss: 1.4477 - accuracy: 0.3442\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 0s 864us/step - loss: 1.4419 - accuracy: 0.3442\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 0s 849us/step - loss: 1.4301 - accuracy: 0.3442\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 0s 854us/step - loss: 1.4534 - accuracy: 0.3377\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 0s 887us/step - loss: 1.4459 - accuracy: 0.3442\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 0s 908us/step - loss: 1.4460 - accuracy: 0.3442\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 0s 967us/step - loss: 1.4437 - accuracy: 0.3442\n",
      "Epoch 180/200\n",
      "77/77 [==============================] - 0s 935us/step - loss: 1.4505 - accuracy: 0.3442\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 0s 933us/step - loss: 1.4489 - accuracy: 0.3442\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 0s 970us/step - loss: 1.4488 - accuracy: 0.3442\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4554 - accuracy: 0.3442\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 0s 836us/step - loss: 1.4420 - accuracy: 0.3442\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 0s 960us/step - loss: 1.4502 - accuracy: 0.3442\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 0s 921us/step - loss: 1.4466 - accuracy: 0.3442\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 0s 953us/step - loss: 1.4522 - accuracy: 0.3442\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 0s 976us/step - loss: 1.4412 - accuracy: 0.3442\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 0s 953us/step - loss: 1.4374 - accuracy: 0.3442\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 0s 973us/step - loss: 1.4375 - accuracy: 0.3442\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 0s 988us/step - loss: 1.4422 - accuracy: 0.3442\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4461 - accuracy: 0.3442\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4409 - accuracy: 0.3442\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4348 - accuracy: 0.3442\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 0s 997us/step - loss: 1.4464 - accuracy: 0.3442\n",
      "Epoch 196/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4500 - accuracy: 0.3442\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 0s 989us/step - loss: 1.4429 - accuracy: 0.3442\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4453 - accuracy: 0.3442\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4526 - accuracy: 0.3442\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 0s 972us/step - loss: 1.4428 - accuracy: 0.3442\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_51\" is incompatible with the layer: expected shape=(None, 10), found shape=(2, 24)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-977-180c2a35ce8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m# 5. 모델 평가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_DNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_DNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'정확도:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\training.py\", line 1471, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\hufss\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_51\" is incompatible with the layer: expected shape=(None, 10), found shape=(2, 24)\n"
     ]
    }
   ],
   "source": [
    "#DNN (은닉층 2개)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "#1. One-hot incoding\n",
    "\n",
    "x_test_DNN = x_test.append([x.loc[x.index == 87]])\n",
    "y_test_DNN = np.append(y_test,y[87])\n",
    "\n",
    "y_train_DNN = to_categorical(y_train)\n",
    "y_test_DNN = to_categorical(y_test_DNN)\n",
    "\n",
    "# 2. 모델 구성\n",
    "model = Sequential()\n",
    "\n",
    "#은닉층 1\n",
    "model.add(Dense(256, input_dim = x_count, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 2\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 3\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 4\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#은닉층 5\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# 4. 모델 학습\n",
    "DNN_model = model.fit(x_train, y_train_DNN, epochs = 200, batch_size = 2)\n",
    "\n",
    "# 5. 모델 평가 \n",
    "score = model.evaluate(x_test_DNN, y_test_DNN, batch_size=2)\n",
    "\n",
    "print('정확도:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESG_Predict_model.pkl']"
      ]
     },
     "execution_count": 976,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(forest, 'ESG_Predict_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
